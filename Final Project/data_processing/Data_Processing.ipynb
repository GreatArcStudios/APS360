{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0g6g7x_ktZN"
   },
   "outputs": [],
   "source": [
    "#this collaboratory notebook will be used for the code for our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bOBO7IwYMsky"
   },
   "outputs": [],
   "source": [
    "#*\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0MBHhru9hvq",
    "outputId": "74a7a292-f241-4af8-d9ea-5f859c96b165"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WkNv7psV7aVq",
    "outputId": "20d6cd6e-ea1c-4773-a99a-237dd0aaf294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.27.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (3.4)\n"
     ]
    }
   ],
   "source": [
    "#*\n",
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfmINayND4Nl"
   },
   "outputs": [],
   "source": [
    "#downloading kaggle file to be able to extract directly from the website -- you need to download a kaggle.json file\n",
    "#to do so:\n",
    "#Go to your Kaggle account settings page and click on \"Create New API Token\". This will download a file called kaggle.json to your local machine.\n",
    "#upload this file to your directory\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QaM8eWCMMray"
   },
   "outputs": [],
   "source": [
    "#*\n",
    "#reading in CSVs\n",
    "#dfnofind is the no findings sheet from NIH images\n",
    "#dfother is allbutnofindings sheet from NIH images\n",
    "dfnofind = pd.read_csv(\"./csv_mappings/nofindv2.csv\")\n",
    "dfother = pd.read_csv(\"./csv_mappings/other_multilabel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "8xiNQIsU_lZb",
    "outputId": "074d0483-e4da-4227-c0b2-f5f5f94358be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_001.png</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51754</th>\n",
       "      <td>00030786_007.png</td>\n",
       "      <td>Consolidation|Pleural_Thickening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51755</th>\n",
       "      <td>00030789_000.png</td>\n",
       "      <td>Infiltration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51756</th>\n",
       "      <td>00030793_000.png</td>\n",
       "      <td>Mass|Nodule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51757</th>\n",
       "      <td>00030795_000.png</td>\n",
       "      <td>Pleural_Thickening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51758</th>\n",
       "      <td>00030801_001.png</td>\n",
       "      <td>Mass|Pneumonia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51759 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image                             class\n",
       "0      00000001_000.png                      Cardiomegaly\n",
       "1      00000001_001.png            Cardiomegaly|Emphysema\n",
       "2      00000001_002.png             Cardiomegaly|Effusion\n",
       "3      00000003_000.png                            Hernia\n",
       "4      00000003_001.png                            Hernia\n",
       "...                 ...                               ...\n",
       "51754  00030786_007.png  Consolidation|Pleural_Thickening\n",
       "51755  00030789_000.png                      Infiltration\n",
       "51756  00030793_000.png                       Mass|Nodule\n",
       "51757  00030795_000.png                Pleural_Thickening\n",
       "51758  00030801_001.png                    Mass|Pneumonia\n",
       "\n",
       "[51759 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#*\n",
    "dfother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O79wL8TbMzyG"
   },
   "outputs": [],
   "source": [
    "#*\n",
    "#getting 10,000 samples of no finding using random state = 0\n",
    "dfsample = dfnofind.sample(n=10000,axis = 0, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pnXZYhi_skB",
    "outputId": "b460164b-5caa-4344-efa6-42c1727bbe68"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61759</td>\n",
       "      <td>61759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>61759</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   image       class\n",
       "count              61759       61759\n",
       "unique             61759         836\n",
       "top     00000001_000.png  No Finding\n",
       "freq                   1       10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#*\n",
    "#concatanate the 10,000 no finding samples with the other samples\n",
    "images = pd.concat([dfother,dfsample])\n",
    "# summary of images \n",
    "images.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_xX0uSEoFArm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                61759\n",
       "unique               61759\n",
       "top       00000001_000.png\n",
       "freq                     1\n",
       "Name: image, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#*\n",
    "#resetting the index since concatenating messes it up and just looking at the image names for extraction\n",
    "imagenames = images['image']\n",
    "imagenames = imagenames.reset_index(drop = True)\n",
    "imagenames.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxdXg5PY-AQS",
    "outputId": "d27e8ab6-2d71-42fb-e31f-6d9d1cf2dc87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'kaggle' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#*\n",
    "#downloading kaggle file for NIH data\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!kaggle datasets download -d nih-chest-xrays/data -p /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vv0X3a_DBsDn",
    "outputId": "e51459a7-a09d-4dc8-e8b1-f6760761b975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARXIV_V5_CHESTXRAY.pdf', 'BBox_List_2017.csv', 'Data_Entry_2017.csv', 'FAQ_CHESTXRAY.pdf', 'LOG_CHESTXRAY.pdf', 'README_CHESTXRAY.pdf', 'images_001/images/00000001_000.png', 'images_001/images/00000001_001.png', 'images_001/images/00000001_002.png', 'images_001/images/00000002_000.png']\n"
     ]
    }
   ],
   "source": [
    "#this is just showing what the file names are for the next piece of code\n",
    "path =  './data/nih_data.zip'\n",
    "import zipfile\n",
    "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "    # Get a list of all the file names in the zip file\n",
    "    file_names = zip_ref.namelist()\n",
    "    print(file_names[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gdk4bLYIArXs"
   },
   "outputs": [],
   "source": [
    "#*\n",
    "from pandas.core.arrays import string_\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "#folder names\n",
    "paths = ['images_001/images/','images_002/images/','images_003/images/','images_004/images/','images_005/images/','images_006/images/','images_007/images/','images_008/images/','images_009/images/','images_010/images/','images_011/images/','images_012/images/']\n",
    "\n",
    "# Set path to zip file\n",
    "zip_path = './data/nih_data.zip'\n",
    "\n",
    "# Extracted images folder \n",
    "extracted_images_path = './data/nih_data/'\n",
    "\n",
    "# Set path to extract or move the renamed images to\n",
    "extractpath = './data/dataimages/'\n",
    "\n",
    "use_zip = False\n",
    "\n",
    "if use_zip:\n",
    "  # Open the zip file\n",
    "  with zipfile.ZipFile(zip_path, 'r') as zip_file:\n",
    "\n",
    "    #loop through images and paths\n",
    "      for i in range(0,len(images)):\n",
    "        for j in range(0,len(paths)):\n",
    "\n",
    "          #create path name using the path and the image name from the dataframe\n",
    "          string = paths[j]+imagenames[i]\n",
    "\n",
    "          # Check if the file exists in the zip file\n",
    "          if string in zip_file.namelist():\n",
    "\n",
    "            # Extract the file\n",
    "            img= zip_file.read(string)\n",
    "\n",
    "            extr = extractpath+imagenames[i]\n",
    "            with open(extr, 'wb') as f:\n",
    "              f.write(img)\n",
    "            # zip_file.extract(string, path=extractpath)\n",
    "            break\n",
    "else:\n",
    "  # instead of using zip file, use the folder\n",
    "  for i in range(0,len(images)):\n",
    "    for j in range(0,len(paths)):\n",
    "\n",
    "      string = extracted_images_path + paths[j]+imagenames[i]\n",
    "      if os.path.exists(string):\n",
    "        shutil.copy(string, extractpath)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "cduw84T3rQsz",
    "outputId": "bbd40062-8821-4289-e1ab-d8099a2f5b1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40963</td>\n",
       "      <td>40963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>40963</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>no finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   image       class\n",
       "count              40963       40963\n",
       "unique             40963          15\n",
       "top     00000001_000.png  no finding\n",
       "freq                   1       10000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#*\n",
    "#sorting the images in the dataframe to be in order based on the image name (this is how they were saved in the file)\n",
    "images2 = images.sort_values(by=['image'])\n",
    "images2= images2.reset_index(drop = True)\n",
    "images2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bFaTmFFn-13j"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "directory = \"./data/images\"\n",
    "classes =  ['no finding', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "  os.makedirs(directory)\n",
    "\n",
    "for i in range(0,len(classes)):\n",
    "  fullpath = directory+'/'+classes[i]\n",
    "  if not os.path.exists(fullpath):\n",
    "    os.makedirs(fullpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "lDsaqjyBklGq"
   },
   "outputs": [],
   "source": [
    "#*\n",
    "#for this i made folders named from 0-14 to be put into\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#creating class folders\n",
    "directory = \"./data/images\"\n",
    "classes =  classes = ['no finding', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
    "\n",
    "#initial folder\n",
    "if not os.path.exists(directory):\n",
    "  os.makedirs(directory)\n",
    "\n",
    "#class folders\n",
    "for i in range(0,len(classes)):\n",
    "  fullpath = directory+'/'+classes[i]\n",
    "  \n",
    "  if not os.path.exists(fullpath):\n",
    "    os.makedirs(fullpath)\n",
    "\n",
    "#sorting images into folders\n",
    "i = -1\n",
    "path = \"./data/dataimages\"\n",
    "\n",
    "for filename in sorted(os.listdir(path)):\n",
    "  #don't want to sort this file\n",
    "  if not filename.endswith(\".ipynb_checkpoints\"):\n",
    "\n",
    "    source = path+'/'+filename\n",
    "    if images2.iloc[i][1] == 'no finding':\n",
    "      dest_path = './data/images/no finding'\n",
    "      shutil.move(source, dest_path)\n",
    "\n",
    "    elif images2.iloc[i][1] == 'Atelectasis':\n",
    "      dest_path = './data/images/Atelectasis'\n",
    "      shutil.move(source, dest_path)\n",
    "\n",
    "    elif images2.iloc[i][1] == 'Cardiomegaly':\n",
    "      dest_path = './data/images/Cardiomegaly'\n",
    "      shutil.move(source, dest_path)\n",
    "\n",
    "    elif images2.iloc[i][1] == 'Consolidation':\n",
    "      dest_path = './data/images/Consolidation'\n",
    "      shutil.move(source, dest_path)\n",
    "\n",
    "    elif images2.iloc[i][1] == 'Edema':\n",
    "      dest_path = './data/images/Edema'\n",
    "      shutil.move(source, dest_path)\n",
    "\n",
    "    elif images2.iloc[i][1] == 'Effusion':\n",
    "      dest_path = './data/images/Effusion'\n",
    "      shutil.move(source, dest_path)\n",
    "\n",
    "    elif images2.iloc[i][1] == 'Emphysema':\n",
    "      dest_path = './data/images/Emphysema'\n",
    "      shutil.move(source, dest_path)\n",
    "\n",
    "    elif images2.iloc[i][1] == 'Fibrosis':\n",
    "      dest_path = './data/images/Fibrosis'\n",
    "      shutil.move(source, dest_path)\n",
    "      \n",
    "    elif images2.iloc[i][1] == 'Hernia':\n",
    "      dest_path = './data/images/Hernia'\n",
    "      shutil.move(source, dest_path)\n",
    "\n",
    "    elif images2.iloc[i][1] == 'Infiltration':\n",
    "      dest_path = './data/images/Infiltration'\n",
    "      shutil.move(source, dest_path)\n",
    "\n",
    "    elif images2.iloc[i][1] == 'Mass':\n",
    "      dest_path = './data/images/Mass'\n",
    "      shutil.move(source, dest_path)\n",
    "\n",
    "    elif images2.iloc[i][1] == 'Nodule':\n",
    "      dest_path = './data/images/Nodule'\n",
    "      shutil.move(source, dest_path)\n",
    "    \n",
    "    elif images2.iloc[i][1] == 'Pleural_Thickening':\n",
    "      dest_path = './data/images/Pleural_Thickening'\n",
    "      shutil.move(source, dest_path)\n",
    "\n",
    "    elif images2.iloc[i][1] == 'Pneumonia':\n",
    "      dest_path = './data/images/Pneumonia'\n",
    "      shutil.move(source, dest_path)\n",
    "\n",
    "    elif images2.iloc[i][1] == 'Pneumothorax':\n",
    "      dest_path = './data/images/Pneumothorax'\n",
    "      shutil.move(source, dest_path)\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4rDqqyC-qvS",
    "outputId": "5e5b0333-b0dd-4c04-8703-49e214f47f4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Downloading pneumothorax-chest-xray-images-and-masks.zip to /content/data\n",
      "100% 4.49G/4.50G [00:31<00:00, 229MB/s]\n",
      "100% 4.50G/4.50G [00:31<00:00, 153MB/s]\n"
     ]
    }
   ],
   "source": [
    "#*\n",
    "#getting kaggle dataset for pneumothorax\n",
    "!kaggle datasets download -d vbookshelf/pneumothorax-chest-xray-images-and-masks -p /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9Q41aBq_E9y",
    "outputId": "63756790-8164-4355-d061-9a3466c41736"
   },
   "outputs": [],
   "source": [
    "#just to check file names\n",
    "with zipfile.ZipFile('./data/pneuthorax.zip', 'r') as zip_ref:\n",
    "    print(zip_ref.namelist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "KaiAeVONAIzK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2_train_1_.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image\n",
       "count             2669\n",
       "unique            2669\n",
       "top     2_train_1_.png\n",
       "freq                 1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#*\n",
    "#importing csv from the pneumothorax sheet from NIH jamges which has the names of images that have a pneumothorax\n",
    "#NOTE this is the pictures not the masks\n",
    "thorax = pd.read_csv(\"./csv_mappings/pneumothorax.csv\")\n",
    "thorax.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "CnYSmXLX-7OH"
   },
   "outputs": [],
   "source": [
    "#*\n",
    "zip_path = './data/pneuthorax.zip'\n",
    "\n",
    "# Set path to extract the zip file to\n",
    "extractpath = './data/images/Pneumothorax'\n",
    "\n",
    "#put all images from the csv into the pneumothorax file\n",
    "path = './data/siim-acr-pneumothorax/png_images/'\n",
    "\n",
    "use_zip = False\n",
    "if use_zip:\n",
    "  # Open the zip file\n",
    "  with zipfile.ZipFile(zip_path, 'r') as zip_file:\n",
    "      for i in range(0,len(thorax)):\n",
    "          string = path+thorax['image'].iloc[i]\n",
    "\n",
    "          img= zip_file.read(string)\n",
    "\n",
    "          extr = extractpath+thorax['image'].iloc[i]\n",
    "          with open(extr, 'wb') as f:\n",
    "            f.write(img)\n",
    "else:\n",
    "  # otherwise copy the respective file from `path`\n",
    "  for i in range(0,len(thorax)):\n",
    "    string = path+thorax['image'].iloc[i]\n",
    "    shutil.copy(string, extractpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mNRyQi0CJBc",
    "outputId": "7bd9d2a5-af4a-4d0c-a5cf-e9e8dbcafbb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Downloading chest-xray-pneumonia.zip to /content\n",
      "100% 2.29G/2.29G [00:14<00:00, 139MB/s]\n",
      "100% 2.29G/2.29G [00:14<00:00, 175MB/s]\n"
     ]
    }
   ],
   "source": [
    "#*\n",
    "#getting pneumonia dataset from kaggle\n",
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "6913EY-FDNMI"
   },
   "outputs": [],
   "source": [
    "#*\n",
    "#extract it to see the different folder names\n",
    "import zipfile\n",
    "with zipfile.ZipFile('./data/chest_xray.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1A2n13SDxJj"
   },
   "outputs": [],
   "source": [
    "#*\n",
    "import shutil\n",
    "\n",
    "#defining paths and folder names\n",
    "folders = ['train/PNEUMONIA', 'val/PNEUMONIA','test/PNEUMONIA']\n",
    "src_dir = './data/chest_xray/'\n",
    "dst_dir = './data/images/Pneumonia'\n",
    "\n",
    "#move all images from the train, validation and testing folders to the pneumonia folder\n",
    "for i in range(0,len(folders)):\n",
    "  dir = src_dir+folders[i]\n",
    "  # loop through all files in the source directory\n",
    "  for filename in os.listdir(dir):\n",
    "          # create the full path to the source and destination files\n",
    "          src_file = os.path.join(dir, filename)\n",
    "          dst_file = os.path.join(dst_dir, filename)\n",
    "          print(src_file, dst_file)\n",
    "          # move the file from the source to the destination folder\n",
    "          shutil.move(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "inVl3Dv2tHxT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim #for gradient descent\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cLCxDwOS9Uws"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Access denied - .\n",
      "File not found - -NAME\n",
      "File not found - -EXEC\n",
      "File not found - RM\n",
      "File not found - -R\n",
      "File not found - {}\n",
      "File not found - +\n"
     ]
    }
   ],
   "source": [
    "#*\n",
    "#removes the .ipnb file which will mess up pytorch if not removed\n",
    "!find . -name \".ipynb_checkpoints\" -exec rm -r {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7D4cFwZEGli"
   },
   "outputs": [],
   "source": [
    "#TRANSFER LEARNING\n",
    "#get dataset from drive\n",
    "#download checkpoint from the github repo\n",
    "#load densenet121\n",
    "#input the checkpoint weights into the densenet \n",
    "#use densenet.features() for each tensor\n",
    "#save to files like lab 3 -- every tensor is saved in a folder for their respective class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LuLNqZULTSD8"
   },
   "outputs": [],
   "source": [
    "p = './data/images'\n",
    "\n",
    "#tensor transformation\n",
    "datatransform = transform=transforms.Compose([\n",
    "                                        transforms.Lambda(lambda x: x.convert('RGB')),\n",
    "                                        transforms.Resize(224),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor()])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(p, transform=datatransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2SJLWbZd4p66"
   },
   "outputs": [],
   "source": [
    "#*\n",
    "#MUST SET SEED TO 26\n",
    "torch.manual_seed(26)\n",
    "tr,val,te = torch.utils.data.random_split(dataset, [28743,9581,9581],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1hFSpa2WI0b2"
   },
   "outputs": [],
   "source": [
    "#normalizing validataion and testing, but not normalizing training yet since it will be rotated etc first\n",
    "datatransform = transform=transforms.Compose([\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "val.transform = transform\n",
    "te.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FGLtkCVTTlZT"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class OversampledImageFolder(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.targets = [label for _, label in dataset]\n",
    "        self.oversampler = RandomOverSampler(sampling_strategy='not majority')\n",
    "        indices = np.arange(len(self.targets)).reshape(-1, 1)\n",
    "        self.indices, self.targets = self.oversampler.fit_resample(indices, self.targets)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        idx = int(self.indices[index])\n",
    "        return self.dataset[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aBKm3DpVGCBC"
   },
   "outputs": [],
   "source": [
    "tr_oversampled = OversampledImageFolder(tr)\n",
    "train = tr_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({14: 10000, 8: 9547, 13: 4863, 12: 4595, 0: 4215, 4: 3955, 10: 2705, 9: 2139, 2: 1310, 11: 1126, 1: 1093, 5: 892, 6: 727, 3: 628, 7: 110}), 47905\n",
      "Oversampled class distribution: Counter({4: 6000, 14: 6000, 9: 6000, 12: 6000, 8: 6000, 13: 6000, 0: 6000, 11: 6000, 6: 6000, 10: 6000, 2: 6000, 5: 6000, 1: 6000, 7: 6000, 3: 6000}), 90000\n"
     ]
    }
   ],
   "source": [
    "print(f'Original class distribution: {Counter(tr.dataset.targets)}, {len(tr.dataset.targets)}')\n",
    "print(f'Oversampled class distribution: {Counter(tr_oversampled.targets)}, {len(tr_oversampled.targets)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9pRsQEy2GrP2"
   },
   "outputs": [],
   "source": [
    "#transformation to do a rotation and flip and also normalize the training dataset\n",
    "#EVEN IF YOU DON\"T WANT TO ROTATE OR FLIP MAKE SURE TO AT LEAST RUN THE NORMALIZE\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation((-15,15)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "train.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hmXefbpi4ucg"
   },
   "outputs": [],
   "source": [
    "trloader = torch.utils.data.DataLoader(train, batch_size=1, shuffle = True)\n",
    "valloader = torch.utils.data.DataLoader(val, batch_size=1,shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(te, batch_size=1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iokYJAlV40fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\pytorch-torchtext\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\envs\\pytorch-torchtext\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure to load the model.pth.tar checkpoint to use\n",
    "import torchvision.models as models\n",
    "checkpoint = torch.load('./model.pth.tar',map_location=torch.device('cpu'))\n",
    "\n",
    "#loading the dictionary of the checkpoint and loading the densent model\n",
    "model = models.densenet121(pretrained=True)\n",
    "model_dict = model.state_dict()\n",
    "saved_state_dict = checkpoint['state_dict']\n",
    "\n",
    "# Modify the keys in the saved state dict to match the keys in your model\n",
    "newdict = {}\n",
    "for key, value in saved_state_dict.items():\n",
    "    new_key = key.replace('densenet121.', '')\n",
    "    new_key = new_key.replace('norm.', 'norm')\n",
    "    new_key = new_key.replace('conv.', 'conv')\n",
    "    new_key = new_key.replace('normr', 'norm.r')\n",
    "    new_key = new_key.replace('normb', 'norm.b')\n",
    "    new_key = new_key.replace('normw', 'norm.w')\n",
    "    new_key = new_key.replace('convw', 'conv.w')\n",
    "    newdict[new_key] = value\n",
    "\n",
    "#ignoring the model checkpoint's classifiers\n",
    "model_dict = model.state_dict()\n",
    "checkpoint_dict = {k: v for k, v in newdict.items() if k in model_dict}\n",
    "model_dict.update(checkpoint_dict)\n",
    "\n",
    "#loading in the model dictionary\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dykwEcd442it"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 1024, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "#* sanity check should get [1,3,224,224] and [1,1024,7,7]\n",
    "for imgs, labels in iter(valloader):\n",
    "    print(imgs.size())\n",
    "    f = model.features(imgs)\n",
    "    print(f.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "XHfqnXBIX4XS"
   },
   "outputs": [],
   "source": [
    "#creating directories\n",
    "folders = ['embeddingtrain','embeddingval', 'embeddingtest']\n",
    "directory = \"./embeddings/\"\n",
    "classes = list(dataset.class_to_idx.keys())\n",
    "\n",
    "#you need a separate folder for train, val and test with all 15 folders in each\n",
    "for i in range(0,len(folders)):\n",
    "  d = directory+folders[i]\n",
    "  #initial folder\n",
    "  if not os.path.exists(d):\n",
    "    os.makedirs(d)\n",
    "\n",
    "  #class folders\n",
    "  for i in range(0,len(classes)):\n",
    "    fullpath = d+'/'+classes[i]\n",
    "  \n",
    "    if not os.path.exists(fullpath):\n",
    "      os.makedirs(fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EM9-6k2hYyzR"
   },
   "outputs": [],
   "source": [
    "#ensure this is run \n",
    "classes = list(dataset.class_to_idx.keys())\n",
    "folders = ['embeddingtrain','embeddingval', 'embeddingtest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "N228yJll44rb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "#creating class folders\n",
    "\n",
    "def get_features(loader,classes,folder):\n",
    "  path ='./embeddings/'+folder\n",
    "  n = 0\n",
    "  for imgs, labels in iter(loader):\n",
    "\n",
    "    label = classes[int(labels[0])]\n",
    "    features = model.features(imgs)\n",
    "    features_tensor = torch.from_numpy(features.detach().numpy())\n",
    "    torch.save(features_tensor.squeeze(0), path +  '/' +label + '/' + str(n)+ '.tensor')\n",
    "    n+=1\n",
    "    if n%1000==0:\n",
    "      print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TlLSmZOe46B-"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "get_features(trloader,classes,folders[0])\n",
    "get_features(valloader,classes,folders[1])\n",
    "get_features(testloader,classes,folders[2])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "pytorch-latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f96540ca9740e0aaa5cb2e15a514a98bd6d11e2fac85bfc91b119a37f695d3d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
