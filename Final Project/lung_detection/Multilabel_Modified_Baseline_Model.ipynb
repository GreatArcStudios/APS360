{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4825,"status":"ok","timestamp":1680726278575,"user":{"displayName":"Margaux","userId":"06529029112575891817"},"user_tz":240},"id":"-oC-pU8L2rkp","outputId":"49951a8f-3c75-4aa2-e98c-709d8274fc76"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.0.0+cu117 True\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import matplotlib.pyplot as plt # for plotting\n","import torch.optim as optim #for gradient descent\n","import torchvision\n","#import torchvision.transforms as transforms\n","#from torch.utils.data.sampler import SubsetRandomSampler\n","import numpy as np\n","\n","torch.manual_seed(1) # set the random seed\n","print(torch.__version__, torch.cuda.is_available())\n","\n","use_cuda = True"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch\n","import os\n","import zipfile\n","import numpy as np\n","import pandas as pd \n","from torchvision.datasets import DatasetFolder\n","from torch.utils import data\n","from lightning import LightningDataModule\n","from torchvision import transforms\n","from torch.utils.data import Dataset, ConcatDataset\n","from imblearn.over_sampling import RandomOverSampler \n","from imblearn.under_sampling import RandomUnderSampler\n","from PIL import Image\n","from concurrent.futures import ThreadPoolExecutor\n","class ImageDataset(Dataset):\n","    def __init__(self, dir, transform=None, load_first=True, testing=True, new_data=False):\n","        self.base_dir = dir\n","        self.nih_dir = dir + r\"\\data\\nih_data\"\n","        self.pneumonia_dir = dir + r\"\\data\\pneumonia\"\n","        self.pneumothorax_dir = dir + r\"\\data\\pneumothorax\"\n","        self.transform = transform\n","        self.load_first = load_first\n","        self.testing = testing\n","        self.new_data = new_data\n","\n","        self.df = self._inital_processing(dir)\n","        \n","        if new_data:\n","            self.labels = torch.FloatTensor(self.df.iloc[:, 1:].values.astype(int)).float()\n","        else:\n","            self.labels = torch.FloatTensor(np.array(self.df.iloc[:, 4:]).astype(int)).float()\n","\n","        if load_first:\n","            self.images = self._load_all_images_parallel()\n","\n","        print(self.nih_dir)\n","        # print(self.labels)\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, index):\n","        if self.load_first:\n","            # obtain image from self.images\n","            image = self.images[index]\n","            img_path = self.base_dir + fr\"\\{self.df.iloc[index, 0]}\"\n","        else:\n","            if not self.new_data:\n","                if self.df.iloc[index,0] == 1:\n","                    img_path = self.nih_dir + fr\"\\{self.df.iloc[index, 1]}\"\n","\n","                #For Pneumothorax Images\n","                elif self.df.iloc[index,0] == 2:\n","                    img_path = self.pneumothorax_dir + fr\"\\{self.df.iloc[index, 1]}\"\n","\n","                #For Pneumonia Images\n","                elif self.df.iloc[index,0] == 3:\n","                    img_path = self.pneumonia_dir + fr\"\\{self.df.iloc[index, 1]}\"\n","            else:\n","                img_path = os.path.join(self.base_dir, self.df.iloc[index, 0])\n","                print(img_path)\n","            # open then close the image to avoid too many open files error\n","            with Image.open(img_path) as image:\n","                image.load()\n","\n","        if self.transform is not None:\n","            image = self.transform(image)\n","\n","        label = self.labels[index]\n","\n","        if self.testing:\n","            return image, label, index, img_path\n","        return image, label\n","    \n","    def _inital_processing(self, dir):\n","        file_name = \"Allimages_onehot.csv\" if not self.new_data else \"newdata_onehot.csv\"\n","        dataset_df = pd.read_csv(os.path.join(dir, \"csv_mappings\", file_name))\n","\n","        if not self.new_data:\n","            # subset only nih data for now by column name\n","            # where only num column == 1\n","            # dataset_df = dataset_df[dataset_df['Num'] == 1]\n","\n","            # undersample the no findings examples\n","            # they are the ones with all 0's as labels\n","            # randomly select 5000 of them\n","            no_findings = dataset_df[dataset_df.iloc[:,4:].sum(axis=1) == 0]\n","            no_findings = no_findings.sample(n=30000, random_state=26)\n","            dataset_df = dataset_df[dataset_df.iloc[:,4:].sum(axis=1) != 0]\n","            dataset_df = pd.concat([dataset_df, no_findings])\n","\n","        return dataset_df\n","\n","    def _load_all_images(self):\n","        images = []\n","        for index in range(len(self.df)):\n","            img_path = self.dir + self.df.iloc[index, 0]\n","            # open then close the image to avoid too many open files error\n","            with open(img_path, 'rb') as image:\n","                image = Image.open(image)\n","                image.load()\n","                images.append(image.convert('RGB'))\n","        return images\n","    \n","    def _load_image(self, start_index, end_index):\n","        images = []\n","        for index in range(start_index, end_index):\n","            if not self.new_data:\n","                if self.df.iloc[index,0] == 1:\n","                    img_path = self.nih_dir + fr\"\\{self.df.iloc[index, 1]}\"\n","                elif self.df.iloc[index,0] == 2:\n","                    img_path = self.pneumothorax_dir + fr\"\\{self.df.iloc[index, 1]}\"\n","                elif self.df.iloc[index,0] == 3:\n","                    img_path = self.pneumonia_dir + fr\"\\{self.df.iloc[index, 1]}\"\n","            else: \n","                print(\"File path:\", self.df.iloc[index, 0])\n","                img_path = self.base_dir +  fr\"\\{self.df.iloc[index, 0]}\"\n","            print(img_path)\n","            # open then close the image to avoid too many open files error\n","            with Image.open(img_path) as image:\n","                image.load()\n","                images.append(image)\n","        return images\n","\n","    def _load_all_images_parallel(self):\n","        # load the images in parallel\n","        # maintain the order of the images\n","        # return a list of images\n","        images = []\n","        with ThreadPoolExecutor() as executor:\n","            # partition job into chunks\n","            chunk_size = 1000\n","            num_chunks = len(self.labels) // chunk_size\n","            for i in range(num_chunks):\n","                start_index = i * chunk_size\n","                end_index = start_index + chunk_size\n","                images += executor.submit(self._load_image, start_index, end_index).result()\n","            # process the remaining images\n","            start_index = num_chunks * chunk_size\n","            end_index = len(self.labels)\n","            images += executor.submit(self._load_image, start_index, end_index).result()\n","\n","        return images\n","\n","class LungDetectionDataModule(LightningDataModule):\n","\n","    def __init__(self, batch_size=2, num_workers=0, master_path=\"\", load_first = True, testing = False, new_data = False):\n","        super().__init__()\n","        self.batch_size = batch_size\n","        self.num_workers = num_workers\n","\n","        self.data_dir = master_path\n","\n","        initial_tranforms = [\n","            transforms.Lambda(lambda x: x.convert('RGB')),\n","            transforms.Resize(256),\n","            transforms.CenterCrop(224),\n","            transforms.ToTensor()\n","        ]\n","        datatransform = transforms.Compose(initial_tranforms)\n","        dataset = self._create_dataset(master_path, datatransform, load_first, testing, new_data)\n","        train_len, val_len = int(len(dataset)*0.8), int(len(dataset)*0.1)\n","        test_len = len(dataset) - train_len - val_len\n","        train, valid, test = torch.utils.data.random_split(\n","            dataset,\n","            [train_len, val_len, test_len],\n","        )\n","        print(\"train: \", len(train), \"valid: \", len(valid), \"test: \", len(test))\n","        self.train = train\n","        self.valid = valid\n","        self.test = test\n","\n","        mean = torch.tensor([0.485, 0.456, 0.406])\n","        std = torch.tensor([0.229, 0.224, 0.225])\n","\n","        non_train_transforms_list = [\n","            transforms.RandomHorizontalFlip(),\n","            transforms.AugMix(severity=6, mixture_width=6),\n","            transforms.TrivialAugmentWide(),\n","            transforms.Normalize(mean=mean, std=std),\n","        ]\n","        non_train_transforms = transforms.Compose(non_train_transforms_list)\n","        self.valid.transform = non_train_transforms\n","        self.test.transform = non_train_transforms\n","\n","        train_transforms_list = [\n","            transforms.RandomHorizontalFlip(),\n","            transforms.AugMix(severity=6, mixture_width=6),\n","            transforms.TrivialAugmentWide(),\n","            transforms.Normalize(mean=mean, std=std),\n","        ]\n","        train_transform = transforms.Compose(train_transforms_list)\n","\n","        self.train.transform = train_transform\n","    \n","    def _create_dataset(self, path, transforms = None, load_first = True, testing = False, new_data = False): \n","        print('new_data: ', new_data)\n","        return ImageDataset(path, transforms, load_first, testing, new_data)\n","    \n","    def train_dataloader(self):\n","        return data.DataLoader(\n","            self.train,\n","            batch_size=self.batch_size,\n","            shuffle=True,\n","            num_workers=self.num_workers,\n","            pin_memory=True\n","        )\n","\n","    def val_dataloader(self):\n","        return data.DataLoader(\n","            self.valid,\n","            batch_size=self.batch_size,\n","            shuffle=False,\n","            num_workers=self.num_workers,\n","            pin_memory=True\n","        )\n","\n","    def test_dataloader(self):\n","        return data.DataLoader(\n","            self.test,\n","            batch_size=self.batch_size,\n","            shuffle=False,\n","            num_workers=self.num_workers,\n","            pin_memory=True\n","        )\n"]},{"cell_type":"markdown","metadata":{"id":"n63AXM0bCk6R"},"source":["# Defining and Training the Model"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":441,"status":"ok","timestamp":1680718950901,"user":{"displayName":"Margaux","userId":"06529029112575891817"},"user_tz":240},"id":"9B54dByW2wq_"},"outputs":[],"source":["#defining the model - CNN with one convolution, make it into it\n","class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        self.conv1 = nn.Conv2d(1024, 1048, 3, 1, 1) #input is over 1000\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.act1 = nn.LeakyReLU()\n","        self.act2 = nn.LeakyReLU()\n","        self.act3 = nn.PReLU()\n","        self.act4 = nn.PReLU()\n","        self.act5 = nn.PReLU()\n","        self.act6 = nn.PReLU()\n","        self.fc1 = nn.Linear(3*3*1048, 2048)\n","        self.fc2 = nn.Linear(2048, 1024)\n","        self.fc3 = nn.Linear(1024, 512)\n","        self.fc4 = nn.Linear(512, 256)\n","        self.fc5 = nn.Linear(256, 96)\n","        self.out = nn.Linear(96, 14) \n","\n","    def forward(self, x):\n","        x = self.pool(self.act1(self.conv1(x)))\n","        x = x.view(-1, 3*3*1048)\n","        x = self.act2(self.fc1(x))\n","        x = self.act3(self.fc2(x))\n","        x = self.act4(self.fc3(x))\n","        x = self.act5(self.fc4(x))\n","        x = self.act6(self.fc5(x))\n","        return self.out(x)\n","\n","model = Classifier()\n","model = model.cuda()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from torchvision import models\n","\n","class BaselinePredictor(nn.Module):\n","    def __init__(self, fine_tune=False, train_from_scratch = False, **kwargs):\n","        super().__init__()\n","        self.baseline_model = Classifier()\n","\n","        if not train_from_scratch:\n","            if fine_tune:\n","                self.dense_model = self._init_dense_model(train_from_scratch)\n","                # don't initially allow the dense model to be trained\n","                for param in self.dense_model.parameters():\n","                    param.requires_grad = False\n","            else:\n","                # create dense net model but freeze the parameters\n","                self.dense_model = self._init_dense_model(train_from_scratch)\n","                for param in self.dense_model.parameters():\n","                    param.requires_grad = False\n","        else:\n","            self.dense_model = self._init_dense_model(train_from_scratch)\n","\n","    def forward(self, input_embeds):\n","        if hasattr(self, 'dense_model'):\n","            input_embeds = self.dense_model(input_embeds)\n","        return self.baseline_model(input_embeds)\n","\n","    def _init_dense_model(self, train_from_scratch):\n","        if not train_from_scratch:\n","            checkpoint = torch.load('../data_processing/model.pth.tar',\n","                                    map_location=torch.device('cuda:0'))\n","            #loading the dictionary of the checkpoint and loading the densent model\n","            dense_model = models.densenet121(pretrained=True, drop_rate=0.3).cuda()\n","            model_dict = dense_model.state_dict()\n","            saved_state_dict = checkpoint['state_dict']\n","\n","            # Modify the keys in the saved state dict to match the keys in your model\n","            newdict = {}\n","            for key, value in saved_state_dict.items():\n","                new_key = key.replace('densenet121.', '')\n","                new_key = new_key.replace('norm.', 'norm')\n","                new_key = new_key.replace('conv.', 'conv')\n","                new_key = new_key.replace('normr', 'norm.r')\n","                new_key = new_key.replace('normb', 'norm.b')\n","                new_key = new_key.replace('normw', 'norm.w')\n","                new_key = new_key.replace('convw', 'conv.w')\n","                newdict[new_key] = value\n","\n","            #ignoring the model checkpoint's classifiers\n","            model_dict = dense_model.state_dict()\n","            checkpoint_dict = {k: v for k, v in newdict.items() if k in model_dict}\n","            model_dict.update(checkpoint_dict)\n","            #loading in the model dictionary\n","            dense_model.load_state_dict(model_dict)\n","        else: \n","            dense_model = models.densenet121(pretrained=False).cuda()\n","        return dense_model.features"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import torchmetrics\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","from torch import nn\n","from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n","from lightning import LightningModule\n","from adamp import AdamP\n","\n","class BaselineLightning(LightningModule):\n","    def __init__(self,\n","                 lr,\n","                 momentum,\n","                 weight_decay,\n","                 gamma=2,\n","                 alpha=None,\n","                 pos_weight_vec = None,\n","                 fine_tune_epoch_start= 20, \n","                 **kwargs):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.model = BaselinePredictor(**kwargs)\n","        self.lr = lr\n","        self.num_classes = kwargs['num_classes']\n","        self.momentum = momentum\n","        self.wd = weight_decay\n","        self.criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_vec)\n","        self.fine_tune_epoch_start = fine_tune_epoch_start\n","        self.is_fine_tuning = False\n","        self.disease_mapping = {\n","            0: \"Atelectasis\",\n","            1: \"Cardiomegaly\",\n","            2: \"Consolidation\",\n","            3: \"Edema\",\n","            4: \"Effusion\",\n","            5: \"Emphysema\",\n","            6: \"Fibrosis\",\n","            7: \"Hernia\",\n","            8: \"Infiltration\",\n","            9: \"Mass\",\n","            10: \"Nodule\",\n","            11: \"Pleural_Thickening\",\n","            12: \"Pneumonia\",\n","            13: \"Pneumothorax\",\n","        }\n","\n","        self.test_results = []\n","\n","    def forward(self, chexnet_embeds):\n","        return self.model(chexnet_embeds)\n","\n","    def training_step(self, batch, batch_idx):\n","        # unfreeze dense net after epoch\n","        if self.current_epoch >= self.fine_tune_epoch_start-1 and not self.is_fine_tuning:\n","            print(f\"Unfreezing DenseNet after {self.fine_tune_epoch_start} epochs\")\n","            for param in self.model.dense_model.parameters():\n","                param.requires_grad = True\n","            self.is_fine_tuning = True\n","\n","        loss, batch_size, train_accuracy, f1_score, f1_score_avg, weighted_f1, auroc = self._process_batch(\n","            batch, True)\n","        self.log('train_loss', loss, batch_size=batch_size, prog_bar=True)\n","        self.log('train_accuracy',\n","                 train_accuracy,\n","                 batch_size=batch_size,\n","                 prog_bar=True)\n","        self.log('train_f1_score', f1_score_avg, batch_size=batch_size)\n","        self.log('train_weighted_f1', weighted_f1, batch_size=batch_size)\n","        self._log_f1_score(f1_score, \"train\", batch_size)\n","        self._log_auroc(auroc, \"train\", batch_size)\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        loss, batch_size, val_accuracy, f1_score, f1_score_avg, weighted_f1, auroc = self._process_batch(\n","            batch, True)\n","        self.log('val_loss',\n","                 loss,\n","                 batch_size=batch_size,\n","                 on_step=False,\n","                 on_epoch=True,\n","                 prog_bar=True)\n","        self.log('val_accuracy',\n","                 val_accuracy,\n","                 batch_size=batch_size,\n","                 on_step=False,\n","                 on_epoch=True,\n","                 prog_bar=True)\n","        self.log('val_f1_score',\n","                 f1_score_avg,\n","                 batch_size=batch_size,\n","                 on_step=False,\n","                 on_epoch=True,\n","                 prog_bar=True)\n","        self.log('val_weighted_f1',\n","                 weighted_f1,\n","                 batch_size=batch_size,\n","                 on_step=False,\n","                 on_epoch=True,\n","                 prog_bar=True)\n","        self._log_f1_score(f1_score, \"val\", batch_size)\n","        self._log_auroc(auroc, \"val\", batch_size)\n","\n","        return loss\n","\n","    def test_step(self, batch, batch_idx):\n","        loss, batch_size, test_accuracy, f1_score, f1_score_avg, weighted_f1, auroc, logits, labels, index, img_path = self._process_batch(\n","            batch, True, True)\n","        self.log('test_loss', loss, batch_size=batch_size, on_epoch=True)\n","        self.log('test_accuracy', test_accuracy, batch_size=batch_size, on_epoch=True)\n","        self.log('test_f1_score', f1_score_avg, batch_size=batch_size, on_epoch=True)\n","        self.log('test_weighted_f1', weighted_f1, batch_size=batch_size, on_epoch=True)\n","        self._log_f1_score(f1_score, \"test\", batch_size, on_epoch=True)\n","        self._log_auroc(auroc, \"test\", batch_size, on_epoch=True)\n","\n","        probs = torch.sigmoid(logits).float().cpu().detach().numpy()\n","        preds = (probs > 0.5).astype(int)\n","        labels = labels.cpu().detach().numpy()\n","        is_correct = (preds == labels).all(axis=1)\n","\n","        self.test_results.append({\n","            \"probs\": probs,\n","            \"prediction\": preds,\n","            \"label\": labels,\n","            \"dataframe_index\": index,\n","            \"img_path\": img_path,\n","            \"is_correct\": is_correct\n","        })\n","\n","        return loss\n","\n","    def configure_optimizers(self):\n","        # optimizer = torch.optim.SGD(\n","        #     self.parameters(), lr=self.lr,\n","        #     weight_decay=self.wd, momentum=self.momentum, nesterov=True)\n","        # optimizer = SGDP(self.parameters(),\n","        #                 lr=self.lr,\n","        #                 weight_decay=self.wd,\n","        #                 momentum=self.momentum,\n","        #                 nesterov=True)\n","        \n","        # optimizer = torch.optim.Adam(self.parameters(),\n","        #                              lr=self.lr,\n","        #                              weight_decay=self.wd)\n","        optimizer = AdamP(self.parameters(), \n","                          lr=self.lr, \n","                          weight_decay=self.wd,\n","                          nesterov=True)\n","        \n","        cosine_anneal = CosineAnnealingLR(optimizer, T_max=6, eta_min=0.00015)\n","        reduce_lr = ReduceLROnPlateau(optimizer, min_lr=0.00001)\n","\n","        return {\n","            \"optimizer\": optimizer,\n","            \"lr_scheduler\": cosine_anneal,\n","            \"monitor\": \"val_loss\"\n","        }\n","\n","    def _process_batch(self, batch, compute_accuracy=False, return_logits = False):\n","        if return_logits:\n","            chexnet_embeds, labels, index, img_path = batch\n","        else:\n","            chexnet_embeds, labels = batch\n","        logits = self(chexnet_embeds)\n","        loss = self.criterion(logits, labels)\n","        if compute_accuracy:\n","            labels = labels.int()\n","            num_labels = int(self.num_classes)\n","\n","            # debug code\n","            #print(F.sigmoid(logits).shape, labels.shape)\n","            # convert logit prob to binary\n","            #bin_preds = torch.round(F.sigmoid(logits)).int()\n","            #print(\"Preds: \", bin_preds, \"labels:\", labels)\n","\n","            accuracy_metric = torchmetrics.Accuracy(task=\"multilabel\",\n","                                                    num_labels=num_labels,\n","                                                    average=\"macro\").cuda()\n","            accuracy = accuracy_metric(logits, labels)\n","            # pytorch f1 score\n","            f1_score_metric = torchmetrics.F1Score(task=\"multilabel\",\n","                                                   num_labels=num_labels,\n","                                                   average='none').cuda()\n","            f1_score = f1_score_metric(logits, labels)\n","            # f1_score = multiclass_f1_score(logits, labels, average=None, num_classes=self.num_classes)\n","            f1_score_avg = f1_score.mean()\n","\n","            weighted_f1_score_metric = torchmetrics.F1Score(\n","                task=\"multilabel\", num_labels=num_labels,\n","                average='weighted').cuda()\n","            weighted_f1_score = weighted_f1_score_metric(logits, labels)\n","\n","            # pytorch auroc scores per class\n","            auroc_metric = torchmetrics.AUROC(task=\"multilabel\",\n","                                              num_labels=num_labels,\n","                                              average=\"none\").cuda()\n","            auroc = auroc_metric(logits, labels)\n","            # auroc = multiclass_auroc(logits, labels, average=None, num_classes=self.num_classes)\n","            if not return_logits:\n","                return loss, len(\n","                    labels\n","                ), accuracy, f1_score, f1_score_avg, weighted_f1_score, auroc\n","            else:\n","                return loss, len(\n","                    labels\n","                ), accuracy, f1_score, f1_score_avg, weighted_f1_score, auroc, logits, labels, index, img_path\n","\n","        return loss, len(labels)\n","\n","    def _log_f1_score(self, f1_score, step_type, batch_size, on_epoch=True):\n","        for i in range(len(f1_score)):\n","            self.log(f\"{step_type}_f1_score_class_{self.disease_mapping[i]}\",\n","                     f1_score[i],\n","                     batch_size=batch_size, on_epoch=on_epoch)\n","\n","    def _log_auroc(self, auroc, step_type, batch_size, on_epoch=True):\n","        for i in range(len(auroc)):\n","            self.log(f\"{step_type}_auroc_class_{self.disease_mapping[i]}\",\n","                     auroc[i],\n","                     batch_size=batch_size, on_epoch=on_epoch)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import wandb\n","import torch\n","import os\n","import csv\n","import numpy as np\n","import pandas as pd\n","from lightning.pytorch.loggers import WandbLogger\n","from lightning.pytorch.callbacks import ModelSummary\n","from lightning.pytorch.callbacks import ModelCheckpoint\n","from lightning.pytorch.callbacks import EarlyStopping\n","from lightning.pytorch.callbacks import LearningRateMonitor\n","from lightning.pytorch.callbacks import StochasticWeightAveraging\n","from lightning.pytorch.trainer import Trainer, seed_everything\n","\n","def train_main(batch_size=128, num_workers=4, max_epochs=50,\n","               master_path=\"\", use_inverse_weighting = False,\n","               pos_weight_multi=1.0, load_first = False, \n","               fine_tune_epoch_start=20, checkpoint_path = None, \n","               testing = False, new_data = False, **kwargs):\n","    # seed experiment\n","    seed_everything(seed=26)\n","\n","    # construct datamodule\n","    datamodule = LungDetectionDataModule(batch_size=batch_size,\n","                                         num_workers=num_workers,\n","                                         master_path=master_path, \n","                                         load_first=load_first, \n","                                         testing=testing,\n","                                         new_data=new_data)\n","    data_size = len(datamodule.train)\n","    if use_inverse_weighting:\n","        targets = [target for _, target in datamodule.train]\n","        class_counts = np.bincount(targets)\n","\n","        # Calculate the class frequencies\n","        class_freqs = class_counts / data_size\n","\n","        # Calculate the inverse frequency weights\n","        weights = 1 / class_freqs\n","    else:\n","        weights = None\n","\n","    # ratio of negative examples to positive examples \n","    # for bce with logits loss \n","    # consider the labels from datamodule.train \n","    num_pos_labels_train = torch.sum(datamodule.train.dataset.labels, dim=0)\n","    num_neg_labels_train = len(datamodule.train) - num_pos_labels_train\n","    pos_weight_vec = num_neg_labels_train / num_pos_labels_train\n","    pos_weight_vec = pos_weight_vec * pos_weight_multi\n","\n","    # construct model\n","    lit_model = BaselineLightning(seed=123,\n","                              batch_size=batch_size,\n","                              num_workers=num_workers,\n","                              data_size=data_size,\n","                              alpha=weights,\n","                              pos_weight_vec=pos_weight_vec,\n","                              fine_tune_epoch_start=fine_tune_epoch_start,\n","                              **kwargs)\n","\n","    # logging\n","    logger = WandbLogger(project=\"lung-xray-baseline\", entity=\"ericzhu\",\n","                         log_model=\"all\", save_dir=\"./wandb_saves\")\n","    logger.experiment.config[\"train_set_len\"] = len(datamodule.train)\n","    logger.experiment.config[\"val_set_len\"] = len(datamodule.valid)\n","    logger.experiment.config[\"batch_size\"] = batch_size\n","\n","    # callbacks\n","    early_stopping = EarlyStopping(\n","        monitor=\"val_f1_score\", mode=\"max\", patience=100)\n","    checkpointing = ModelCheckpoint(\n","        monitor=\"val_f1_score\", mode=\"max\", save_top_k=5)\n","    stochastic_weighting = StochasticWeightAveraging(swa_epoch_start=0.75,\n","                                                     annealing_epochs=8,\n","                                                     swa_lrs=0.0003)\n","    model_sumary = ModelSummary(max_depth=4)\n","    learning_rate_montior = LearningRateMonitor(logging_interval=\"step\")\n","    # training\n","    trainer = Trainer(\n","        callbacks=[early_stopping, checkpointing, model_sumary,\n","                   learning_rate_montior],\n","        devices=\"auto\",\n","        logger=logger,\n","        enable_progress_bar=True,\n","        log_every_n_steps=1,\n","        max_epochs=max_epochs,\n","        precision=\"bf16-mixed\",\n","    )\n","    if not testing:\n","        trainer.fit(lit_model, datamodule=datamodule, ckpt_path=checkpoint_path)\n","    else:\n","        test_results = trainer.test(lit_model, datamodule=datamodule, ckpt_path=checkpoint_path)\n","        wandb.finish()\n","        return test_results, lit_model\n","\n","    wandb.finish()\n","\n","    return lit_model"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mericzhu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.14.1 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.14.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>c:\\Users\\ericz\\Documents\\GitHub\\APS360\\Final Project\\lung_detection\\wandb\\run-20230407_095712-nsujpjqe</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/ericzhu/lung-xray/runs/nsujpjqe' target=\"_blank\">apricot-valley-356</a></strong> to <a href='https://wandb.ai/ericzhu/lung-xray' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/ericzhu/lung-xray' target=\"_blank\">https://wandb.ai/ericzhu/lung-xray</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/ericzhu/lung-xray/runs/nsujpjqe' target=\"_blank\">https://wandb.ai/ericzhu/lung-xray/runs/nsujpjqe</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-8by6l2gg:v0, 443.84MB. 1 files... \n","\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n","Done. 0:0:0.2\n","Global seed set to 26\n"]},{"name":"stdout","output_type":"stream","text":["C:\\Users\\ericz\\Documents\\Github\\APS360\\Final Project\\data_processing\\data\\nih_data\n","train:  70960 valid:  8870 test:  8871\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\ericz\\anaconda3\\envs\\pytorch-latest\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","c:\\Users\\ericz\\anaconda3\\envs\\pytorch-latest\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","c:\\Users\\ericz\\anaconda3\\envs\\pytorch-latest\\lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n","  rank_zero_warn(\n","Using bfloat16 Automatic Mixed Precision (AMP)\n","Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","Restoring states from the checkpoint path at .\\artifacts\\model-8by6l2gg-v0\\model.ckpt\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Loaded model weights from the checkpoint at .\\artifacts\\model-8by6l2gg-v0\\model.ckpt\n","c:\\Users\\ericz\\anaconda3\\envs\\pytorch-latest\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1eb833b42cd4707ac6db5086af82ecb","version_major":2,"version_minor":0},"text/plain":["Testing: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\Users\\ericz\\anaconda3\\envs\\pytorch-latest\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n","  warnings.warn(*args, **kwargs)\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\">              Test metric               </span>┃<span style=\"font-weight: bold\">              DataLoader 0              </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│<span style=\"color: #008080; text-decoration-color: #008080\">             test_accuracy              </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.9295457005500793           </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">      test_auroc_class_Atelectasis      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.5                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">     test_auroc_class_Cardiomegaly      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.5                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">     test_auroc_class_Consolidation     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.5                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">         test_auroc_class_Edema         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.5                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">       test_auroc_class_Effusion        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.5                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">       test_auroc_class_Emphysema       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.5                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">       test_auroc_class_Fibrosis        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.5                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">        test_auroc_class_Hernia         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.2885807752609253           </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">     test_auroc_class_Infiltration      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.5                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">         test_auroc_class_Mass          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.5                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">        test_auroc_class_Nodule         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.5                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">  test_auroc_class_Pleural_Thickening   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.5                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">       test_auroc_class_Pneumonia       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.5                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">     test_auroc_class_Pneumothorax      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.5                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">             test_f1_score              </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">    test_f1_score_class_Atelectasis     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">    test_f1_score_class_Cardiomegaly    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">   test_f1_score_class_Consolidation    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">       test_f1_score_class_Edema        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_score_class_Effusion      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_score_class_Emphysema      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_score_class_Fibrosis      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">       test_f1_score_class_Hernia       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">    test_f1_score_class_Infiltration    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">        test_f1_score_class_Mass        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">       test_f1_score_class_Nodule       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\"> test_f1_score_class_Pleural_Thickening </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_score_class_Pneumonia      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">    test_f1_score_class_Pneumothorax    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">               test_loss                </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">            test_weighted_f1            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.0                   </span>│\n","└────────────────────────────────────────┴────────────────────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m             Test metric              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m             DataLoader 0             \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m            test_accuracy             \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.9295457005500793          \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m     test_auroc_class_Atelectasis     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.5                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m    test_auroc_class_Cardiomegaly     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.5                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m    test_auroc_class_Consolidation    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.5                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m        test_auroc_class_Edema        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.5                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m      test_auroc_class_Effusion       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.5                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m      test_auroc_class_Emphysema      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.5                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m      test_auroc_class_Fibrosis       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.5                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m       test_auroc_class_Hernia        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.2885807752609253          \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m    test_auroc_class_Infiltration     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.5                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m        test_auroc_class_Mass         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.5                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m       test_auroc_class_Nodule        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.5                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m test_auroc_class_Pleural_Thickening  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.5                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m      test_auroc_class_Pneumonia      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.5                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m    test_auroc_class_Pneumothorax     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.5                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m            test_f1_score             \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m   test_f1_score_class_Atelectasis    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m   test_f1_score_class_Cardiomegaly   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m  test_f1_score_class_Consolidation   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m      test_f1_score_class_Edema       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m     test_f1_score_class_Effusion     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m    test_f1_score_class_Emphysema     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m     test_f1_score_class_Fibrosis     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m      test_f1_score_class_Hernia      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m   test_f1_score_class_Infiltration   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m       test_f1_score_class_Mass       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m      test_f1_score_class_Nodule      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36mtest_f1_score_class_Pleural_Thickening\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m    test_f1_score_class_Pneumonia     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m   test_f1_score_class_Pneumothorax   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m              test_loss               \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m           test_weighted_f1           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.0                  \u001b[0m\u001b[35m \u001b[0m│\n","└────────────────────────────────────────┴────────────────────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_auroc_class_Atelectasis</td><td>▁</td></tr><tr><td>test_auroc_class_Cardiomegaly</td><td>▁</td></tr><tr><td>test_auroc_class_Consolidation</td><td>▁</td></tr><tr><td>test_auroc_class_Edema</td><td>▁</td></tr><tr><td>test_auroc_class_Effusion</td><td>▁</td></tr><tr><td>test_auroc_class_Emphysema</td><td>▁</td></tr><tr><td>test_auroc_class_Fibrosis</td><td>▁</td></tr><tr><td>test_auroc_class_Hernia</td><td>▁</td></tr><tr><td>test_auroc_class_Infiltration</td><td>▁</td></tr><tr><td>test_auroc_class_Mass</td><td>▁</td></tr><tr><td>test_auroc_class_Nodule</td><td>▁</td></tr><tr><td>test_auroc_class_Pleural_Thickening</td><td>▁</td></tr><tr><td>test_auroc_class_Pneumonia</td><td>▁</td></tr><tr><td>test_auroc_class_Pneumothorax</td><td>▁</td></tr><tr><td>test_f1_score</td><td>▁</td></tr><tr><td>test_f1_score_class_Atelectasis</td><td>▁</td></tr><tr><td>test_f1_score_class_Cardiomegaly</td><td>▁</td></tr><tr><td>test_f1_score_class_Consolidation</td><td>▁</td></tr><tr><td>test_f1_score_class_Edema</td><td>▁</td></tr><tr><td>test_f1_score_class_Effusion</td><td>▁</td></tr><tr><td>test_f1_score_class_Emphysema</td><td>▁</td></tr><tr><td>test_f1_score_class_Fibrosis</td><td>▁</td></tr><tr><td>test_f1_score_class_Hernia</td><td>▁</td></tr><tr><td>test_f1_score_class_Infiltration</td><td>▁</td></tr><tr><td>test_f1_score_class_Mass</td><td>▁</td></tr><tr><td>test_f1_score_class_Nodule</td><td>▁</td></tr><tr><td>test_f1_score_class_Pleural_Thickening</td><td>▁</td></tr><tr><td>test_f1_score_class_Pneumonia</td><td>▁</td></tr><tr><td>test_f1_score_class_Pneumothorax</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_weighted_f1</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>test_accuracy</td><td>0.92955</td></tr><tr><td>test_auroc_class_Atelectasis</td><td>0.5</td></tr><tr><td>test_auroc_class_Cardiomegaly</td><td>0.5</td></tr><tr><td>test_auroc_class_Consolidation</td><td>0.5</td></tr><tr><td>test_auroc_class_Edema</td><td>0.5</td></tr><tr><td>test_auroc_class_Effusion</td><td>0.5</td></tr><tr><td>test_auroc_class_Emphysema</td><td>0.5</td></tr><tr><td>test_auroc_class_Fibrosis</td><td>0.5</td></tr><tr><td>test_auroc_class_Hernia</td><td>0.28858</td></tr><tr><td>test_auroc_class_Infiltration</td><td>0.5</td></tr><tr><td>test_auroc_class_Mass</td><td>0.5</td></tr><tr><td>test_auroc_class_Nodule</td><td>0.5</td></tr><tr><td>test_auroc_class_Pleural_Thickening</td><td>0.5</td></tr><tr><td>test_auroc_class_Pneumonia</td><td>0.5</td></tr><tr><td>test_auroc_class_Pneumothorax</td><td>0.5</td></tr><tr><td>test_f1_score</td><td>0.0</td></tr><tr><td>test_f1_score_class_Atelectasis</td><td>0.0</td></tr><tr><td>test_f1_score_class_Cardiomegaly</td><td>0.0</td></tr><tr><td>test_f1_score_class_Consolidation</td><td>0.0</td></tr><tr><td>test_f1_score_class_Edema</td><td>0.0</td></tr><tr><td>test_f1_score_class_Effusion</td><td>0.0</td></tr><tr><td>test_f1_score_class_Emphysema</td><td>0.0</td></tr><tr><td>test_f1_score_class_Fibrosis</td><td>0.0</td></tr><tr><td>test_f1_score_class_Hernia</td><td>0.0</td></tr><tr><td>test_f1_score_class_Infiltration</td><td>0.0</td></tr><tr><td>test_f1_score_class_Mass</td><td>0.0</td></tr><tr><td>test_f1_score_class_Nodule</td><td>0.0</td></tr><tr><td>test_f1_score_class_Pleural_Thickening</td><td>0.0</td></tr><tr><td>test_f1_score_class_Pneumonia</td><td>0.0</td></tr><tr><td>test_f1_score_class_Pneumothorax</td><td>0.0</td></tr><tr><td>test_loss</td><td>0.0</td></tr><tr><td>test_weighted_f1</td><td>0.0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">apricot-valley-356</strong> at: <a href='https://wandb.ai/ericzhu/lung-xray/runs/nsujpjqe' target=\"_blank\">https://wandb.ai/ericzhu/lung-xray/runs/nsujpjqe</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>.\\wandb\\run-20230407_095712-nsujpjqe\\logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[{'test_loss': 0.0, 'test_accuracy': 0.9295457005500793, 'test_f1_score': 0.0, 'test_weighted_f1': 0.0, 'test_f1_score_class_Atelectasis': 0.0, 'test_f1_score_class_Cardiomegaly': 0.0, 'test_f1_score_class_Consolidation': 0.0, 'test_f1_score_class_Edema': 0.0, 'test_f1_score_class_Effusion': 0.0, 'test_f1_score_class_Emphysema': 0.0, 'test_f1_score_class_Fibrosis': 0.0, 'test_f1_score_class_Hernia': 0.0, 'test_f1_score_class_Infiltration': 0.0, 'test_f1_score_class_Mass': 0.0, 'test_f1_score_class_Nodule': 0.0, 'test_f1_score_class_Pleural_Thickening': 0.0, 'test_f1_score_class_Pneumonia': 0.0, 'test_f1_score_class_Pneumothorax': 0.0, 'test_auroc_class_Atelectasis': 0.5, 'test_auroc_class_Cardiomegaly': 0.5, 'test_auroc_class_Consolidation': 0.5, 'test_auroc_class_Edema': 0.5, 'test_auroc_class_Effusion': 0.5, 'test_auroc_class_Emphysema': 0.5, 'test_auroc_class_Fibrosis': 0.5, 'test_auroc_class_Hernia': 0.2885807752609253, 'test_auroc_class_Infiltration': 0.5, 'test_auroc_class_Mass': 0.5, 'test_auroc_class_Nodule': 0.5, 'test_auroc_class_Pleural_Thickening': 0.5, 'test_auroc_class_Pneumonia': 0.5, 'test_auroc_class_Pneumothorax': 0.5}]\n"]}],"source":["torch.set_float32_matmul_precision(\"medium\")\n","master_path = r'C:\\Users\\ericz\\Documents\\Github\\APS360\\Final Project\\data_processing'\n","train = False\n","if train:\n","    train_configs = {\n","        \"master_path\": master_path,\n","        \"batch_size\": 256,\n","        \"num_workers\": 0,\n","        \"max_epochs\": 5,\n","        \"lr\": 0.006,\n","        \"weight_decay\": 8e-8,\n","        \"momentum\": 0.98,\n","        \"gamma\": 2, \n","        \"use_inverse_weighting\": False,\n","        \"num_classes\": 14,\n","        \"fine_tune\": False,\n","        \"fine_tune_epoch_start\": 40,\n","        \"pos_weight_multi\": 0,\n","        \"train_from_scratch\": True,\n","        \"load_first\": True,\n","    }\n","    baseline_model = train_main(**train_configs)\n","else:\n","    run = wandb.init(project=\"lung-xray\", entity=\"ericzhu\",)\n","    artifact = run.use_artifact(\n","        'ericzhu/lung-xray-baseline/model-8by6l2gg:v0', type='model')\n","    artifact_dir = artifact.download()\n","    model_checkpoint = os.path.join(artifact_dir, \"model.ckpt\")\n","    train_configs = {\n","        \"master_path\": master_path,\n","        \"batch_size\": 256,\n","        \"num_workers\": 0,\n","        \"max_epochs\": 5,\n","        \"lr\": 0.006,\n","        \"weight_decay\": 8e-8,\n","        \"momentum\": 0.98,\n","        \"gamma\": 2, \n","        \"use_inverse_weighting\": False,\n","        \"num_classes\": 14,\n","        \"fine_tune\": True,\n","        \"fine_tune_epoch_start\": 40,\n","        \"pos_weight_multi\": 0,\n","        \"train_from_scratch\": False,\n","        \"load_first\": False,\n","        \"checkpoint_path\": model_checkpoint,\n","        \"testing\": not train,\n","        \"new_data\": True,\n","    }\n","    test_results, eval_model = train_main(**train_configs)\n","    print(test_results)\n","\n","    # save test results to txt file\n","    with open(\"test_results.txt\", \"w\") as f:\n","        f.write(str(test_results))\n","\n","    test_results = eval_model.test_results\n","    test_results_df = pd.DataFrame(test_results)\n","    test_results_df.to_csv(\"test_predictions.csv\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Pytorch20","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"1b359cbce28cfdeeac83dcaa24271bc1308b37fc25c47ff1f45c1f32b5e130d7"}}},"nbformat":4,"nbformat_minor":0}
