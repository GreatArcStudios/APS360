<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>lab3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="Lab3_files/libs/clipboard/clipboard.min.js"></script>
<script src="Lab3_files/libs/quarto-html/quarto.js"></script>
<script src="Lab3_files/libs/quarto-html/popper.min.js"></script>
<script src="Lab3_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Lab3_files/libs/quarto-html/anchor.min.js"></script>
<link href="Lab3_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Lab3_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Lab3_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Lab3_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Lab3_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="lab-3-gesture-recognition-using-convolutional-neural-networks" class="level1">
<h1>Lab 3: Gesture Recognition using Convolutional Neural Networks</h1>
<p>In this lab you will train a convolutional neural network to make classifications on different hand gestures. By the end of the lab, you should be able to:</p>
<ol type="1">
<li>Load and split data for training, validation and testing</li>
<li>Train a Convolutional Neural Network</li>
<li>Apply transfer learning to improve your model</li>
</ol>
<p>Note that for this lab we will not be providing you with any starter code. You should be able to take the code used in previous labs, tutorials and lectures and modify it accordingly to complete the tasks outlined below.</p>
<section id="what-to-submit" class="level3">
<h3 class="anchored" data-anchor-id="what-to-submit">What to submit</h3>
<p>Submit a PDF file containing all your code, outputs, and write-up from parts 1-5. You can produce a PDF of your Google Colab file by going to <strong>File &gt; Print</strong> and then save as PDF. The Colab instructions has more information. Make sure to review the PDF submission to ensure that your answers are easy to read. Make sure that your text is not cut off at the margins.</p>
<p><strong>Do not submit any other files produced by your code.</strong></p>
<p>Include a link to your colab file in your submission.</p>
<p>Please use Google Colab to complete this assignment. If you want to use Jupyter Notebook, please complete the assignment and upload your Jupyter Notebook file to Google Colab for submission.</p>
</section>
<section id="colab-link" class="level2">
<h2 class="anchored" data-anchor-id="colab-link">Colab Link</h2>
<p>Include a link to your colab file here</p>
<p>Colab Link:</p>
<p><a href="https://colab.research.google.com/github/GreatArcStudios/APS360/blob/master/Lab%203/Lab3.ipynb">https://colab.research.google.com/github/GreatArcStudios/APS360/blob/master/Lab%203/Lab3.ipynb</a></p>
</section>
<section id="dataset" class="level2">
<h2 class="anchored" data-anchor-id="dataset">Dataset</h2>
<p>American Sign Language (ASL) is a complete, complex language that employs signs made by moving the hands combined with facial expressions and postures of the body. It is the primary language of many North Americans who are deaf and is one of several communication options used by people who are deaf or hard-of-hearing. The hand gestures representing English alphabet are shown below. This lab focuses on classifying a subset of these hand gesture images using convolutional neural networks. Specifically, given an image of a hand showing one of the letters A-I, we want to detect which letter is being represented.</p>
<p><img src="https://www.disabled-world.com/pics/1/asl-alphabet.jpg" class="img-fluid"></p>
</section>
<section id="part-b.-building-a-cnn-50-pt" class="level2">
<h2 class="anchored" data-anchor-id="part-b.-building-a-cnn-50-pt">Part B. Building a CNN [50 pt]</h2>
<p>For this lab, we are not going to give you any starter code. You will be writing a convolutional neural network from scratch. You are welcome to use any code from previous labs, lectures and tutorials. You should also write your own code.</p>
<p>You may use the PyTorch documentation freely. You might also find online tutorials helpful. However, all code that you submit must be your own.</p>
<p>Make sure that your code is vectorized, and does not contain obvious inefficiencies (for example, unecessary for loops, or unnecessary calls to unsqueeze()). Ensure enough comments are included in the code so that your TA can understand what you are doing. It is your responsibility to show that you understand what you write.</p>
<p><strong>This is much more challenging and time-consuming than the previous labs.</strong> Make sure that you give yourself plenty of time by starting early.</p>
<section id="data-loading-and-splitting-5-pt" class="level3">
<h3 class="anchored" data-anchor-id="data-loading-and-splitting-5-pt">1. Data Loading and Splitting [5 pt]</h3>
<p>Download the anonymized data provided on Quercus. To allow you to get a heads start on this project we will provide you with sample data from previous years. Split the data into training, validation, and test sets.</p>
<p>Note: Data splitting is not as trivial in this lab. We want our test set to closely resemble the setting in which our model will be used. In particular, our test set should contain hands that are never seen in training!</p>
<p>Explain how you split the data, either by describing what you did, or by showing the code that you used. Justify your choice of splitting strategy. How many training, validation, and test images do you have?</p>
<p>For loading the data, you can use plt.imread as in Lab 1, or any other method that you choose. You may find torchvision.datasets.ImageFolder helpful. (see https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=image%20folder#torchvision.datasets.ImageFolder )</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> pip install tqdm </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> pip install torchinfo</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: tqdm in c:\programdata\anaconda3\envs\pytorch-latest\lib\site-packages (4.64.1)
Requirement already satisfied: colorama in c:\programdata\anaconda3\envs\pytorch-latest\lib\site-packages (from tqdm) (0.4.6)
Requirement already satisfied: torchinfo in c:\users\ericz\appdata\roaming\python\python310\site-packages (1.7.1)</code></pre>
</div>
</div>
<div class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-execution_count="107">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># imports</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, random_split</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> trange</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchinfo <span class="im">import</span> summary</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># create dataloaders</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_datasets(to_tensor<span class="op">=</span><span class="va">True</span>, small_set_adjustment<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    transforms <span class="op">=</span> [torchvision.transforms.Normalize((<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), (<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>))]</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> to_tensor:</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        transforms.insert(<span class="dv">0</span>, torchvision.transforms.ToTensor())</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    transforms <span class="op">=</span> torchvision.transforms.Compose(transforms)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    images_dataset <span class="op">=</span> torchvision.datasets.ImageFolder(</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./Dataset"</span>, transform<span class="op">=</span>transforms)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    leftover_prob <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> <span class="fl">0.7</span> <span class="op">*</span> small_set_adjustment <span class="op">-</span> <span class="fl">0.1</span> <span class="op">*</span> small_set_adjustment <span class="op">-</span> <span class="fl">0.2</span> <span class="op">*</span> small_set_adjustment</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    split_sets <span class="op">=</span> random_split(images_dataset, [</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>                              <span class="fl">0.7</span> <span class="op">*</span> small_set_adjustment, <span class="fl">0.1</span> <span class="op">*</span> small_set_adjustment, <span class="fl">0.2</span> <span class="op">*</span> small_set_adjustment, leftover_prob])</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> split_sets</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_dataloaders(split_sets, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>, use_cuda<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    train_set, val_set, test_set <span class="op">=</span> split_sets</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>    train_loader <span class="op">=</span> DataLoader(</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>        train_set, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span>shuffle, pin_memory<span class="op">=</span>use_cuda)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    val_loader <span class="op">=</span> DataLoader(val_set, batch_size<span class="op">=</span><span class="bu">len</span>(</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>        val_set), shuffle<span class="op">=</span>shuffle, pin_memory<span class="op">=</span>use_cuda)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    test_loader <span class="op">=</span> DataLoader(test_set, batch_size<span class="op">=</span><span class="bu">len</span>(</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>        test_set), shuffle<span class="op">=</span>shuffle, pin_memory<span class="op">=</span>use_cuda)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_loader, val_loader, test_loader</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="model-building-and-sanity-checking-15-pt" class="level3">
<h3 class="anchored" data-anchor-id="model-building-and-sanity-checking-15-pt">2. Model Building and Sanity Checking [15 pt]</h3>
</section>
<section id="part-a-convolutional-network---5-pt" class="level3">
<h3 class="anchored" data-anchor-id="part-a-convolutional-network---5-pt">Part (a) Convolutional Network - 5 pt</h3>
<p>Build a convolutional neural network model that takes the (224x224 RGB) image as input, and predicts the gesture letter. Your model should be a subclass of nn.Module. Explain your choice of neural network architecture: how many layers did you choose? What types of layers did you use? Were they fully-connected or convolutional? What about other decisions like pooling layers, activation functions, number of channels / hidden units?</p>
<div class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-execution_count="97">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleCNN(nn.Module):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, conv_dilation<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.feature_embeddings <span class="op">=</span> nn.Sequential(</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>            <span class="co"># produces shape 9, 200, 200</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">3</span>, <span class="dv">9</span>, <span class="dv">26</span>),</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>            nn.Mish(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>            <span class="co"># produces shape 9, 99, 99</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>            nn.AvgPool2d(<span class="dv">4</span>, <span class="dv">2</span>),</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>            nn.Mish(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>            <span class="co"># produces shape 4, 93, 93</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">9</span>, <span class="dv">4</span>, <span class="dv">3</span>, dilation<span class="op">=</span>conv_dilation),</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>            nn.Mish(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(<span class="dv">3</span>),</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>            nn.Mish(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">2</span>),</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>            nn.Mish(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            nn.AvgPool2d(<span class="dv">2</span>),</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>            nn.Mish(inplace<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># programmatically get feature embedding size </span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._feature_embed_size <span class="op">=</span> <span class="bu">list</span>(<span class="va">self</span>.feature_embeddings(torch.rand(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">224</span>, <span class="dv">224</span>)).detach().size())</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedding_size <span class="op">=</span> np.prod(<span class="va">self</span>._feature_embed_size)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># use dropout to regularize model </span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(p<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flatten <span class="op">=</span> nn.Flatten()</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># autoencoder like architecture - just remove reconstruction layers</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="va">self</span>.embedding_size, <span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">2</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act1 <span class="op">=</span> nn.Mish()</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">2</span>, <span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">4</span>)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act2 <span class="op">=</span> nn.Mish()</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc3 <span class="op">=</span> nn.Linear(<span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">4</span>, <span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">4</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act3 <span class="op">=</span> nn.Mish()</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc4 <span class="op">=</span> nn.Linear(<span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">4</span>, <span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">2</span>)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act4 <span class="op">=</span> nn.Mish()</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc5 <span class="op">=</span> nn.Linear(<span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">2</span>, <span class="dv">9</span>)</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># create latent space rep.</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.flatten(<span class="va">self</span>.feature_embeddings(<span class="bu">input</span>))</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.act1(<span class="va">self</span>.fc1(z))</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.dropout(z)</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.act2(<span class="va">self</span>.fc2(z))</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.dropout(z)</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.act3(<span class="va">self</span>.fc3(z))</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.dropout(z)</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.act4(<span class="va">self</span>.fc4(z))</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.dropout(z)</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.fc5(z)</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I constructed my neural network first with a stack of convolution and pooling layers. This was done to get compressed latent feature representations that I could then feed into various linear layers motivated by the autoencoder architecture, but with the final reconstruction layers removed. I decided on adding quite a few convolution layers because I wanted to feed higher level feature representations into the fully connected layers, which would be further tuned in the latent space by the fully connected layers. Also, I chose to output 9 feature representations (output channel dimension of 9) in the first convolution layer because just wanted some extra granularity in learned kernels (more learned kernels) since each feature representation is only generated by one kernel. I used a dilated convolution since traditional convolution kernels considers only adjacent pixels, and so I used the dilated convolution to increase the receptive field, which allows for me to capture the potentially useful dependencies between further apart elements in the feature representations. I used average pooling after the first convolution layer since I wanted to average out “sharp” signals rather than have the network focus on the most intense values of the low level features. My final pooling layer also used average pooling for the same reason but for higher level features; I wanted the fully connected layers to be fed what was “generally” going on in some image. I used dropout to help prevent overfitting of the rather dense fully connected layers (the first one has more than half of the total parameters), and allows for essentially model averaging (https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf). Further, my linear layers were constructed in an autoencoder like fashion, i.e., we project into a smaller latent space, forcing the network to further learn what was actually important, and then projected it back up for the final output layer. Finally, I used the Mish activation since it can create much smoother loss landscapes (https://arxiv.org/pdf/1908.08681.pdf).</p>
</section>
<section id="part-b-training-code---5-pt" class="level3">
<h3 class="anchored" data-anchor-id="part-b-training-code---5-pt">Part (b) Training Code - 5 pt</h3>
<p>Write code that trains your neural network given some training data. Your training code should make it easy to tweak the usual hyperparameters, like batch size, learning rate, and the model object itself. Make sure that you are checkpointing your models from time to time (the frequency is up to you). Explain your choice of loss function and optimizer.</p>
<div class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-execution_count="96">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_loss(preds, targets):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> criterion(preds, targets)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_loop(train_loader, val_loader, convolution_dilation<span class="op">=</span><span class="dv">2</span>, epochs<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.02</span>, momentum<span class="op">=</span><span class="fl">0.95</span>, wd<span class="op">=</span><span class="fl">1e-4</span>, batch_size<span class="op">=</span><span class="va">None</span>, train_data<span class="op">=</span><span class="va">None</span>, use_cuda<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> use_cuda <span class="kw">and</span> torch.cuda.is_available():</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        dev <span class="op">=</span> <span class="st">"cuda:0"</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"CUDA unavailable, training on CPU"</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        dev <span class="op">=</span> <span class="st">"CPU"</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(dev)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    network <span class="op">=</span> SimpleCNN(conv_dilation<span class="op">=</span>convolution_dilation)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    network <span class="op">=</span> network.to(device)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.SGD(network.parameters(</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    ), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span>momentum, weight_decay<span class="op">=</span>wd)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> train_data <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        summary(network, input_data<span class="op">=</span>train_data, verbose<span class="op">=</span><span class="dv">1</span>, device<span class="op">=</span>device)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    loss_dict <span class="op">=</span> {<span class="st">"config"</span>: <span class="ss">f"Convolution Dilation: </span><span class="sc">{</span>convolution_dilation<span class="sc">}</span><span class="ss">, Epochs: </span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss">, Lr: </span><span class="sc">{</span>learning_rate<span class="sc">}</span><span class="ss">, Momentum:</span><span class="sc">{</span>momentum<span class="sc">}</span><span class="ss">, Weight Decay: </span><span class="sc">{</span>wd<span class="sc">}</span><span class="ss">, Batch Size: </span><span class="sc">{</span>batch_size<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"train_loss"</span>: [], <span class="st">"val_loss"</span>: [],</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"train_acc"</span>: [], <span class="st">"val_acc"</span>: []}</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> trange(epochs, desc<span class="op">=</span><span class="st">"Train epochs"</span>, unit<span class="op">=</span><span class="st">"epoch"</span>) <span class="im">as</span> train_bar:</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> train_bar:</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>            epoch_loss, val_loss <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">0.0</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>            train_correct, train_total <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">0.0</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>            val_correct, val_total <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">0.0</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>                <span class="co"># reenable train mode to enable dropout</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>                network.train()</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>                inputs, targets <span class="op">=</span> batch</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>                inputs <span class="op">=</span> inputs.to(device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>                targets <span class="op">=</span> targets.to(device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>                network.zero_grad()</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>                preds <span class="op">=</span> network(inputs)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> compute_loss(preds, targets)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>                loss.backward()</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>                optimizer.step()</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>                <span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># eval mode to disable dropout</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>                    network.<span class="bu">eval</span>()</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>                    epoch_loss <span class="op">+=</span> loss.item()</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>                    _, category_preds <span class="op">=</span> torch.<span class="bu">max</span>(preds, <span class="dv">1</span>)</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>                    train_correct <span class="op">+=</span> <span class="bu">float</span>((category_preds <span class="op">==</span></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>                                           targets).<span class="bu">sum</span>().item())</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>                    train_total <span class="op">+=</span> <span class="bu">float</span>(<span class="bu">len</span>(preds))</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>                    loss_dict[<span class="st">"train_loss"</span>].append(loss.item())</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>                    loss_dict[<span class="st">"train_acc"</span>].append(train_correct<span class="op">/</span>train_total)</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(val_loader):</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>                    inputs, targets <span class="op">=</span> batch</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>                    inputs <span class="op">=</span> inputs.to(device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>                    targets <span class="op">=</span> targets.to(device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>                    preds <span class="op">=</span> network(inputs)</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>                    batch_val_loss <span class="op">=</span> compute_loss(preds, targets).item()</span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>                    val_loss <span class="op">+=</span> batch_val_loss</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>                    _, category_preds <span class="op">=</span> torch.<span class="bu">max</span>(preds, <span class="dv">1</span>)</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>                    val_correct <span class="op">+=</span> <span class="bu">float</span>((category_preds <span class="op">==</span></span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>                                         targets).<span class="bu">sum</span>().item())</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>                    val_total <span class="op">+=</span> <span class="bu">float</span>(<span class="bu">len</span>(preds))</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>                    loss_dict[<span class="st">"val_loss"</span>].append(batch_val_loss)</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>                    loss_dict[<span class="st">"val_acc"</span>].append(val_correct<span class="op">/</span>val_total)</span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>            train_bar.set_postfix(epoch_loss<span class="op">=</span>epoch_loss,</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>                                  train_acc<span class="op">=</span>train_correct<span class="op">/</span>train_total,</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>                                  train_correct<span class="op">=</span>train_correct,</span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>                                  train_total<span class="op">=</span>train_total,</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>                                  val_loss<span class="op">=</span>val_loss,</span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>                                  val_acc<span class="op">=</span>val_correct<span class="op">/</span>val_total)</span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> network, loss_dict</span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_test_performance(network, test_loader):</span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>    test_correct, test_total <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">0.0</span></span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>    test_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> <span class="bu">next</span>(network.parameters()).device</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a>        <span class="co"># disable dropout for test time</span></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>        network.<span class="bu">eval</span>()</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(test_loader):</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a>            inputs, targets <span class="op">=</span> batch</span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> inputs.to(device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>            targets <span class="op">=</span> targets.to(device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> network(inputs)</span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>            test_loss <span class="op">+=</span> compute_loss(preds, targets).item()</span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a>            _, category_preds <span class="op">=</span> torch.<span class="bu">max</span>(preds, <span class="dv">1</span>)</span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a>            test_correct <span class="op">+=</span> <span class="bu">float</span>((category_preds <span class="op">==</span> targets).<span class="bu">sum</span>().item())</span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a>            test_total <span class="op">+=</span> <span class="bu">len</span>(preds)</span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> test_correct<span class="op">/</span>test_total, test_correct, test_total, test_loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I chose cross entropy loss since our task is a mutliclass prediction task, and so we essentially need to output logits to define a multinomial distribution for the hand signs. In other words, our task is to fit a conditional distribution that is a vector of probabilities when conditioned on some image, i.e., for some image <span class="math inline">\(\mathbf{x}\)</span> and some vector of hand sign classes <span class="math inline">\(\mathbf{c}\)</span>, we fit <span class="math inline">\(p(\mathbf{c} \mid \mathbf{x})\)</span>. Cross entropy loss allows us to do this from an output layer (https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).</p>
<p>Then, I chose SGD as the optimizer because SGD is theoretically guaranteed to converge to the minimum norm solution (assuming a convex objective function, e.g., linear regression), while adaptive optimizers like Adam are not guaranteed to do so (https://openreview.net/pdf?id=ryQu7f-RZ). Additionally, SGD also implements momentum, so it has the added benefit of potentially being able to escape certain local minima.</p>
</section>
<section id="part-c-overfit-to-a-small-dataset---5-pt" class="level3">
<h3 class="anchored" data-anchor-id="part-c-overfit-to-a-small-dataset---5-pt">Part (c) “Overfit” to a Small Dataset - 5 pt</h3>
<p>One way to sanity check our neural network model and training code is to check whether the model is capable of “overfitting” or “memorizing” a small dataset. A properly constructed CNN with correct training code should be able to memorize the answers to a small number of images quickly.</p>
<p>Construct a small dataset (e.g.&nbsp;just the images that you have collected). Then show that your model and training code is capable of memorizing the labels of this small data set.</p>
<p>With a large batch size (e.g.&nbsp;the entire small dataset) and learning rate that is not too high, You should be able to obtain a 100% training accuracy on that small dataset relatively quickly (within 200 iterations).</p>
<div class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-execution_count="105">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> training_wrapper(convolution_dilation<span class="op">=</span><span class="dv">2</span>, epochs<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.02</span>, momentum<span class="op">=</span><span class="fl">0.95</span>, wd<span class="op">=</span><span class="fl">1e-4</span>, batch_size<span class="op">=</span><span class="va">None</span>, train_data<span class="op">=</span><span class="va">None</span>, use_cuda<span class="op">=</span><span class="va">True</span>, small_set_adjustment <span class="op">=</span> <span class="fl">1.0</span>):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    use_cuda <span class="op">=</span> <span class="va">True</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    train_set, val_set, test_set, _ <span class="op">=</span> create_datasets(small_set_adjustment<span class="op">=</span>small_set_adjustment)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    split_sets <span class="op">=</span> (train_set, val_set, test_set)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="bu">len</span>(train_set))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    train_batch_size <span class="op">=</span> <span class="bu">len</span>(train_set) <span class="cf">if</span> batch_size <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> batch_size</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    train_loader, val_loader, test_loader <span class="op">=</span> create_dataloaders(</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        split_sets, batch_size<span class="op">=</span>train_batch_size, use_cuda<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># used for torch info summary</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> use_cuda <span class="kw">and</span> torch.cuda.is_available():</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        dev <span class="op">=</span> <span class="st">"cuda:0"</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"CUDA unavailable, training on CPU"</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        dev <span class="op">=</span> <span class="st">"CPU"</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(dev)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    dummy_data <span class="op">=</span> torch.rand((train_batch_size, <span class="dv">3</span>, <span class="dv">224</span>, <span class="dv">224</span>)).to(device)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    trained_network, loss_dict <span class="op">=</span> train_loop(train_loader, val_loader, convolution_dilation<span class="op">=</span>convolution_dilation,</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>                                            epochs<span class="op">=</span>epochs, learning_rate<span class="op">=</span>learning_rate, momentum<span class="op">=</span>momentum, wd<span class="op">=</span>wd,</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>                                            batch_size<span class="op">=</span>train_batch_size, train_data<span class="op">=</span>dummy_data, use_cuda<span class="op">=</span>use_cuda)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> trained_network, loss_dict, (train_loader, val_loader, test_loader)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="109">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>trained_network, loss_dict, _ <span class="op">=</span> training_wrapper(epochs<span class="op">=</span><span class="dv">30</span>, small_set_adjustment<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>311
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
SimpleCNN                                [311, 9]                  --
├─Sequential: 1-1                        [311, 2, 15, 15]          --
│    └─Conv2d: 2-1                       [311, 9, 199, 199]        18,261
│    └─Mish: 2-2                         [311, 9, 199, 199]        --
│    └─AvgPool2d: 2-3                    [311, 9, 98, 98]          --
│    └─Mish: 2-4                         [311, 9, 98, 98]          --
│    └─Conv2d: 2-5                       [311, 4, 94, 94]          328
│    └─Mish: 2-6                         [311, 4, 94, 94]          --
│    └─MaxPool2d: 2-7                    [311, 4, 31, 31]          --
│    └─Mish: 2-8                         [311, 4, 31, 31]          --
│    └─Conv2d: 2-9                       [311, 2, 30, 30]          34
│    └─Mish: 2-10                        [311, 2, 30, 30]          --
│    └─AvgPool2d: 2-11                   [311, 2, 15, 15]          --
│    └─Mish: 2-12                        [311, 2, 15, 15]          --
├─Flatten: 1-2                           [311, 450]                --
├─Linear: 1-3                            [311, 225]                101,475
├─Mish: 1-4                              [311, 225]                --
├─Dropout: 1-5                           [311, 225]                --
├─Linear: 1-6                            [311, 112]                25,312
├─Mish: 1-7                              [311, 112]                --
├─Dropout: 1-8                           [311, 112]                --
├─Linear: 1-9                            [311, 112]                12,656
├─Mish: 1-10                             [311, 112]                --
├─Dropout: 1-11                          [311, 112]                --
├─Linear: 1-12                           [311, 225]                25,425
├─Mish: 1-13                             [311, 225]                --
├─Dropout: 1-14                          [311, 225]                --
├─Linear: 1-15                           [311, 9]                  2,034
==========================================================================================
Total params: 185,525
Trainable params: 185,525
Non-trainable params: 0
Total mult-adds (G): 225.86
==========================================================================================
Input size (MB): 187.26
Forward/backward pass size (MB): 980.86
Params size (MB): 0.74
Estimated Total Size (MB): 1168.86
==========================================================================================</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Train epochs: 100%|██████████| 30/30 [00:14&lt;00:00,  2.01epoch/s, epoch_loss=0.00677, train_acc=1, train_correct=311, train_total=311, val_acc=1, val_loss=0.00509]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>torch.cuda.empty_cache() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="hyperparameter-search-10-pt" class="level3">
<h3 class="anchored" data-anchor-id="hyperparameter-search-10-pt">3. Hyperparameter Search [10 pt]</h3>
</section>
<section id="part-a---1-pt" class="level3">
<h3 class="anchored" data-anchor-id="part-a---1-pt">Part (a) - 1 pt</h3>
<p>List 3 hyperparameters that you think are most worth tuning. Choose at least one hyperparameter related to the model architecture.</p>
<p>I could try tuning the following hyperparameters:</p>
<ol type="1">
<li>The convolution dilation scale to tune how far apart the elements used in the convolution operation will be chosen. This would affect the latent representations, but choosing a good value would lead to better representations across the image, i.e., learn features far apart in the image that are informative to the ASL sign.</li>
<li>I could also tune the learning rate since in the overfit example it seems to converge slower than it needs to even though both the validation and train losses are virtually 0, and the model scored 100% accuracy on both sets respectively.</li>
<li>I could try tuning the weight decay parameter as it is essentially a <span class="math inline">\(L_2\)</span> penalty and can help the model converge to a local minima of the loss surface that is well regularized, and thus potentially perform better on the test set.</li>
</ol>
</section>
<section id="part-b---5-pt" class="level3">
<h3 class="anchored" data-anchor-id="part-b---5-pt">Part (b) - 5 pt</h3>
<p>Tune the hyperparameters you listed in Part (a), trying as many values as you need to until you feel satisfied that you are getting a good model. Plot the training curve of at least 4 different hyperparameter settings.</p>
<p>I tested the hyperparameter changes I discussed above. Note that I plotted the batch number vs accuracy/loss for the training curves since otherwise the curves for the accuracy would look like a straight line up to one, and I wouldn’t be able to investigate how it changed over time. In other words, there wasn’t enough granularity in the curves by just plotting epoch vs accuracy/loss.</p>
<div class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-execution_count="110">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_train_curves(loss_dict):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"</span><span class="sc">{</span>loss_dict[<span class="st">'config'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(loss_dict[<span class="st">"train_acc"</span>])</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    plt.plot(<span class="bu">range</span>(<span class="dv">1</span>,n<span class="op">+</span><span class="dv">1</span>), loss_dict[<span class="st">"train_acc"</span>], label<span class="op">=</span><span class="st">"Train Accuracy"</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    plt.plot(<span class="bu">range</span>(<span class="dv">1</span>,n<span class="op">+</span><span class="dv">1</span>), loss_dict[<span class="st">"train_loss"</span>], label<span class="op">=</span><span class="st">"Train Loss"</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Batch"</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Loss/Error"</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    plt.legend(loc<span class="op">=</span><span class="st">'best'</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_val_curves(loss_dict):</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"</span><span class="sc">{</span>loss_dict[<span class="st">'config'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(loss_dict[<span class="st">"val_acc"</span>])</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    plt.plot(<span class="bu">range</span>(<span class="dv">1</span>,n<span class="op">+</span><span class="dv">1</span>), loss_dict[<span class="st">"val_acc"</span>], label<span class="op">=</span><span class="st">"Validation Accuracy"</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    plt.plot(<span class="bu">range</span>(<span class="dv">1</span>,n<span class="op">+</span><span class="dv">1</span>), loss_dict[<span class="st">"val_loss"</span>], label<span class="op">=</span><span class="st">"Validation Loss"</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Epoch"</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Loss/Accuracy"</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    plt.legend(loc<span class="op">=</span><span class="st">'best'</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With the default hyperparameters, we see the following graphs:</p>
<div class="cell" data-execution_count="111">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>plot_train_curves(loss_dict)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>plot_val_curves(loss_dict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Lab3_files/figure-html/cell-10-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Lab3_files/figure-html/cell-10-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>My first experiment is changing the convolution dilation parameter to 4, which drastically increases the receptive field since distances between points on the kernel are now doubled.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>trained_network_dilation_change, loss_dict_dilation, _ <span class="op">=</span> training_wrapper(epochs<span class="op">=</span><span class="dv">30</span>, convolution_dilation<span class="op">=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
SimpleCNN                                [1554, 9]                 --
├─Sequential: 1-1                        [1554, 2, 14, 14]         --
│    └─Conv2d: 2-1                       [1554, 9, 199, 199]       18,261
│    └─Mish: 2-2                         [1554, 9, 199, 199]       --
│    └─AvgPool2d: 2-3                    [1554, 9, 98, 98]         --
│    └─Mish: 2-4                         [1554, 9, 98, 98]         --
│    └─Conv2d: 2-5                       [1554, 4, 90, 90]         328
│    └─Mish: 2-6                         [1554, 4, 90, 90]         --
│    └─MaxPool2d: 2-7                    [1554, 4, 30, 30]         --
│    └─Mish: 2-8                         [1554, 4, 30, 30]         --
│    └─Conv2d: 2-9                       [1554, 2, 29, 29]         34
│    └─Mish: 2-10                        [1554, 2, 29, 29]         --
│    └─AvgPool2d: 2-11                   [1554, 2, 14, 14]         --
│    └─Mish: 2-12                        [1554, 2, 14, 14]         --
├─Flatten: 1-2                           [1554, 392]               --
├─Linear: 1-3                            [1554, 196]               77,028
├─Mish: 1-4                              [1554, 196]               --
├─Dropout: 1-5                           [1554, 196]               --
├─Linear: 1-6                            [1554, 98]                19,306
├─Mish: 1-7                              [1554, 98]                --
├─Dropout: 1-8                           [1554, 98]                --
├─Linear: 1-9                            [1554, 98]                9,702
├─Mish: 1-10                             [1554, 98]                --
├─Dropout: 1-11                          [1554, 98]                --
├─Linear: 1-12                           [1554, 196]               19,404
├─Mish: 1-13                             [1554, 196]               --
├─Dropout: 1-14                          [1554, 196]               --
├─Linear: 1-15                           [1554, 9]                 1,773
==========================================================================================
Total params: 145,836
Trainable params: 145,836
Non-trainable params: 0
Total mult-adds (T): 1.13
==========================================================================================
Input size (MB): 935.68
Forward/backward pass size (MB): 4862.01
Params size (MB): 0.58
Estimated Total Size (MB): 5798.27
==========================================================================================</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Train epochs: 100%|██████████| 30/30 [01:32&lt;00:00,  3.09s/epoch, epoch_loss=0.00671, train_acc=1, train_correct=1554.0, train_total=1554.0, val_acc=1, val_loss=0.00507]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>plot_train_curves(loss_dict_dilation)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>plot_val_curves(loss_dict_dilation)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Lab3_files/figure-html/cell-12-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Lab3_files/figure-html/cell-12-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>My second experiment is the learning rate. Since the model converges to perfect accuracy on both the train and validation sets long before the 30 epochs, we can tune the learning rate to be a bit higher. We do not seem to need to take as small steps towards minima.</p>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>trained_network_lr_change, loss_dict_lr, _ <span class="op">=</span> training_wrapper(epochs<span class="op">=</span><span class="dv">30</span>, learning_rate<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
SimpleCNN                                [1554, 9]                 --
├─Sequential: 1-1                        [1554, 2, 15, 15]         --
│    └─Conv2d: 2-1                       [1554, 9, 199, 199]       18,261
│    └─Mish: 2-2                         [1554, 9, 199, 199]       --
│    └─AvgPool2d: 2-3                    [1554, 9, 98, 98]         --
│    └─Mish: 2-4                         [1554, 9, 98, 98]         --
│    └─Conv2d: 2-5                       [1554, 4, 94, 94]         328
│    └─Mish: 2-6                         [1554, 4, 94, 94]         --
│    └─MaxPool2d: 2-7                    [1554, 4, 31, 31]         --
│    └─Mish: 2-8                         [1554, 4, 31, 31]         --
│    └─Conv2d: 2-9                       [1554, 2, 30, 30]         34
│    └─Mish: 2-10                        [1554, 2, 30, 30]         --
│    └─AvgPool2d: 2-11                   [1554, 2, 15, 15]         --
│    └─Mish: 2-12                        [1554, 2, 15, 15]         --
├─Flatten: 1-2                           [1554, 450]               --
├─Linear: 1-3                            [1554, 225]               101,475
├─Mish: 1-4                              [1554, 225]               --
├─Dropout: 1-5                           [1554, 225]               --
├─Linear: 1-6                            [1554, 112]               25,312
├─Mish: 1-7                              [1554, 112]               --
├─Dropout: 1-8                           [1554, 112]               --
├─Linear: 1-9                            [1554, 112]               12,656
├─Mish: 1-10                             [1554, 112]               --
├─Dropout: 1-11                          [1554, 112]               --
├─Linear: 1-12                           [1554, 225]               25,425
├─Mish: 1-13                             [1554, 225]               --
├─Dropout: 1-14                          [1554, 225]               --
├─Linear: 1-15                           [1554, 9]                 2,034
==========================================================================================
Total params: 185,525
Trainable params: 185,525
Non-trainable params: 0
Total mult-adds (T): 1.13
==========================================================================================
Input size (MB): 935.68
Forward/backward pass size (MB): 4901.14
Params size (MB): 0.74
Estimated Total Size (MB): 5837.57
==========================================================================================</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Train epochs: 100%|██████████| 30/30 [01:31&lt;00:00,  3.04s/epoch, epoch_loss=0, train_acc=1, train_correct=1554.0, train_total=1554.0, val_acc=1, val_loss=0]            </code></pre>
</div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>plot_train_curves(loss_dict_lr)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>plot_val_curves(loss_dict_lr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Lab3_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Lab3_files/figure-html/cell-14-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>My third experiment is increasing the weight decay parameter since this could help us in finding a set of parameters for the model that corresponding to a well regularized model, which could help us mitigate possibly biases (e.g., inductive biases in making the model).</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>trained_network_wd_change, loss_dict_wd, _ <span class="op">=</span> training_wrapper(epochs<span class="op">=</span><span class="dv">30</span>, wd<span class="op">=</span><span class="fl">0.01</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
SimpleCNN                                [1554, 9]                 --
├─Sequential: 1-1                        [1554, 2, 15, 15]         --
│    └─Conv2d: 2-1                       [1554, 9, 199, 199]       18,261
│    └─Mish: 2-2                         [1554, 9, 199, 199]       --
│    └─AvgPool2d: 2-3                    [1554, 9, 98, 98]         --
│    └─Mish: 2-4                         [1554, 9, 98, 98]         --
│    └─Conv2d: 2-5                       [1554, 4, 94, 94]         328
│    └─Mish: 2-6                         [1554, 4, 94, 94]         --
│    └─MaxPool2d: 2-7                    [1554, 4, 31, 31]         --
│    └─Mish: 2-8                         [1554, 4, 31, 31]         --
│    └─Conv2d: 2-9                       [1554, 2, 30, 30]         34
│    └─Mish: 2-10                        [1554, 2, 30, 30]         --
│    └─AvgPool2d: 2-11                   [1554, 2, 15, 15]         --
│    └─Mish: 2-12                        [1554, 2, 15, 15]         --
├─Flatten: 1-2                           [1554, 450]               --
├─Linear: 1-3                            [1554, 225]               101,475
├─Mish: 1-4                              [1554, 225]               --
├─Dropout: 1-5                           [1554, 225]               --
├─Linear: 1-6                            [1554, 112]               25,312
├─Mish: 1-7                              [1554, 112]               --
├─Dropout: 1-8                           [1554, 112]               --
├─Linear: 1-9                            [1554, 112]               12,656
├─Mish: 1-10                             [1554, 112]               --
├─Dropout: 1-11                          [1554, 112]               --
├─Linear: 1-12                           [1554, 225]               25,425
├─Mish: 1-13                             [1554, 225]               --
├─Dropout: 1-14                          [1554, 225]               --
├─Linear: 1-15                           [1554, 9]                 2,034
==========================================================================================
Total params: 185,525
Trainable params: 185,525
Non-trainable params: 0
Total mult-adds (T): 1.13
==========================================================================================
Input size (MB): 935.68
Forward/backward pass size (MB): 4901.14
Params size (MB): 0.74
Estimated Total Size (MB): 5837.57
==========================================================================================</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Train epochs: 100%|██████████| 30/30 [01:29&lt;00:00,  2.99s/epoch, epoch_loss=0.00881, train_acc=1, train_correct=1554.0, train_total=1554.0, val_acc=1, val_loss=0.00687]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>plot_train_curves(loss_dict_wd)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>plot_val_curves(loss_dict_wd)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Lab3_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Lab3_files/figure-html/cell-16-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Finally, I will change the batch size to a much smaller batch size and combine all of these changes. Smaller batch sizes can help avoid overfitting as their gradients are computed from randomly sampled minibatches, and so the optimizer steps will be less homogenous and can therefore help explore the loss surface more.</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>trained_network_all_change, loss_dict_all, _ <span class="op">=</span> training_wrapper(epochs<span class="op">=</span><span class="dv">30</span>, wd<span class="op">=</span><span class="fl">0.01</span>, batch_size<span class="op">=</span><span class="dv">64</span>, learning_rate<span class="op">=</span><span class="fl">0.008</span>, convolution_dilation<span class="op">=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
SimpleCNN                                [64, 9]                   --
├─Sequential: 1-1                        [64, 2, 14, 14]           --
│    └─Conv2d: 2-1                       [64, 9, 199, 199]         18,261
│    └─Mish: 2-2                         [64, 9, 199, 199]         --
│    └─AvgPool2d: 2-3                    [64, 9, 98, 98]           --
│    └─Mish: 2-4                         [64, 9, 98, 98]           --
│    └─Conv2d: 2-5                       [64, 4, 90, 90]           328
│    └─Mish: 2-6                         [64, 4, 90, 90]           --
│    └─MaxPool2d: 2-7                    [64, 4, 30, 30]           --
│    └─Mish: 2-8                         [64, 4, 30, 30]           --
│    └─Conv2d: 2-9                       [64, 2, 29, 29]           34
│    └─Mish: 2-10                        [64, 2, 29, 29]           --
│    └─AvgPool2d: 2-11                   [64, 2, 14, 14]           --
│    └─Mish: 2-12                        [64, 2, 14, 14]           --
├─Flatten: 1-2                           [64, 392]                 --
├─Linear: 1-3                            [64, 196]                 77,028
├─Mish: 1-4                              [64, 196]                 --
├─Dropout: 1-5                           [64, 196]                 --
├─Linear: 1-6                            [64, 98]                  19,306
├─Mish: 1-7                              [64, 98]                  --
├─Dropout: 1-8                           [64, 98]                  --
├─Linear: 1-9                            [64, 98]                  9,702
├─Mish: 1-10                             [64, 98]                  --
├─Dropout: 1-11                          [64, 98]                  --
├─Linear: 1-12                           [64, 196]                 19,404
├─Mish: 1-13                             [64, 196]                 --
├─Dropout: 1-14                          [64, 196]                 --
├─Linear: 1-15                           [64, 9]                   1,773
==========================================================================================
Total params: 145,836
Trainable params: 145,836
Non-trainable params: 0
Total mult-adds (G): 46.46
==========================================================================================
Input size (MB): 38.54
Forward/backward pass size (MB): 200.24
Params size (MB): 0.58
Estimated Total Size (MB): 239.36
==========================================================================================</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Train epochs: 100%|██████████| 30/30 [01:19&lt;00:00,  2.66s/epoch, epoch_loss=0.272, train_acc=1, train_correct=1554.0, train_total=1554.0, val_acc=1, val_loss=0.0106] </code></pre>
</div>
</div>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>plot_train_curves(loss_dict_all)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>plot_val_curves(loss_dict_all)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Lab3_files/figure-html/cell-18-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Lab3_files/figure-html/cell-18-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="part-c---2-pt" class="level3">
<h3 class="anchored" data-anchor-id="part-c---2-pt">Part (c) - 2 pt</h3>
<p>Choose the best model out of all the ones that you have trained. Justify your choice.</p>
<p>I choose my best model to be the combined model that has changes to all of the tested hyperparameters. While all of the models have perfect training and validation accuracy, this model used a smaller minibatch size, meaning that it was able to get more hetergeneous estimates of the true gradient. As such, it likely explored the loss surface more, and perhaps it has a more reliable set of parameters. In particular, large minibatch sizes (&gt; 512) appear to converge to sharp minima according to <a href="https://arxiv.org/pdf/1609.04836.pdf">Keskar et al.</a>, which lead to worse generalization performance.</p>
</section>
<section id="part-d---2-pt" class="level3">
<h3 class="anchored" data-anchor-id="part-d---2-pt">Part (d) - 2 pt</h3>
<p>Report the test accuracy of your best model. You should only do this step once and prior to this step you should have only used the training and validation data.</p>
<div class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-execution_count="42">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>train_set, val_set, test_set <span class="op">=</span> create_datasets()</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>split_sets <span class="op">=</span> (train_set, val_set, test_set)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>_, _, test_loader <span class="op">=</span> create_dataloaders(</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    split_sets, batch_size<span class="op">=</span><span class="dv">64</span>, use_cuda<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>test_acc, test_correct, test_total, test_loss <span class="op">=</span> compute_test_performance(trained_network_all_change, test_loader)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_acc, test_loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.0 0.010579031892120838</code></pre>
</div>
</div>
<p>The test accuracy is 100%, so the model was able to perfectly classify all of the hand signs as it did with the training and validation sets!</p>
</section>
<section id="transfer-learning-15-pt" class="level3">
<h3 class="anchored" data-anchor-id="transfer-learning-15-pt">4. Transfer Learning [15 pt]</h3>
<p>For many image classification tasks, it is generally not a good idea to train a very large deep neural network model from scratch due to the enormous compute requirements and lack of sufficient amounts of training data.</p>
<p>One of the better options is to try using an existing model that performs a similar task to the one you need to solve. This method of utilizing a pre-trained network for other similar tasks is broadly termed <strong>Transfer Learning</strong>. In this assignment, we will use Transfer Learning to extract features from the hand gesture images. Then, train a smaller network to use these features as input and classify the hand gestures.</p>
<p>As you have learned from the CNN lecture, convolution layers extract various features from the images which get utilized by the fully connected layers for correct classification. AlexNet architecture played a pivotal role in establishing Deep Neural Nets as a go-to tool for image classification problems and we will use an ImageNet pre-trained AlexNet model to extract features in this assignment.</p>
</section>
<section id="part-a---5-pt" class="level3">
<h3 class="anchored" data-anchor-id="part-a---5-pt">Part (a) - 5 pt</h3>
<p>Here is the code to load the AlexNet network, with pretrained weights. When you first run the code, PyTorch will download the pretrained weights from the internet.</p>
<div class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-execution_count="2">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.models</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> torchvision.models.alexnet(pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> alexnet.to(device<span class="op">=</span><span class="st">"cuda:0"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>c:\ProgramData\Anaconda3\envs\pytorch-latest\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
c:\ProgramData\Anaconda3\envs\pytorch-latest\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)</code></pre>
</div>
</div>
<p>The alexnet model is split up into two components: <em>alexnet.features</em> and <em>alexnet.classifier</em>. The first neural network component, <em>alexnet.features</em>, is used to compute convolutional features, which are taken as input in <em>alexnet.classifier</em>.</p>
<p>The neural network alexnet.features expects an image tensor of shape Nx3x224x224 as input and it will output a tensor of shape Nx256x6x6 . (N = batch size).</p>
<p>Compute the AlexNet features for each of your training, validation, and test data. Here is an example code snippet showing how you can compute the AlexNet features for some images (your actual code might be different):</p>
<div class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-execution_count="65">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># img = ... a PyTorch tensor with shape [N,3,224,224] containing hand images ...</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>train_set, val_set, test_set <span class="op">=</span> create_datasets()</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>split_sets <span class="op">=</span> (train_set, val_set, test_set)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>train_loader, val_loader, test_loader <span class="op">=</span> create_dataloaders(split_sets, batch_size<span class="op">=</span><span class="bu">len</span>(train_set))</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>train_embeds, val_embeds, test_embeds <span class="op">=</span> <span class="va">None</span>, <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>train_targets, val_targets, test_targets <span class="op">=</span> <span class="va">None</span>, <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">input</span>, targets <span class="op">=</span> batch</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">input</span> <span class="op">=</span> <span class="bu">input</span>.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> targets.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>    train_embeds <span class="op">=</span> alexnet.features(<span class="bu">input</span>)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>    train_targets <span class="op">=</span> targets</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(val_loader):</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">input</span>, targets <span class="op">=</span> batch</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">input</span> <span class="op">=</span> <span class="bu">input</span>.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> targets.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>    val_embeds <span class="op">=</span> alexnet.features(<span class="bu">input</span>)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    val_targets <span class="op">=</span> targets</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(test_loader):</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">input</span>, targets <span class="op">=</span> batch</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">input</span> <span class="op">=</span> <span class="bu">input</span>.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> targets.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>    test_embeds <span class="op">=</span> alexnet.features(<span class="bu">input</span>)</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>    test_targets <span class="op">=</span> targets</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>train_embeds.size(), val_embeds.size(), test_embeds.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>(torch.Size([1554, 256, 6, 6]),
 torch.Size([222, 256, 6, 6]),
 torch.Size([443, 256, 6, 6]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>torch.save(train_embeds, <span class="st">"./train_embeds"</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>torch.save(val_embeds, <span class="st">"./val_embeds"</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>torch.save(test_embeds, <span class="st">"./test_embeds"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Save the computed features</strong>. You will be using these features as input to your neural network in Part (b), and you do not want to re-compute the features every time. Instead, run <em>alexnet.features</em> once for each image, and save the result.</p>
</section>
<section id="part-b---3-pt" class="level3">
<h3 class="anchored" data-anchor-id="part-b---3-pt">Part (b) - 3 pt</h3>
<p>Build a convolutional neural network model that takes as input these AlexNet features, and makes a prediction. Your model should be a subclass of nn.Module.</p>
<p>Explain your choice of neural network architecture: how many layers did you choose? What types of layers did you use: fully-connected or convolutional? What about other decisions like pooling layers, activation functions, number of channels / hidden units in each layer?</p>
<p>Here is an example of how your model may be called:</p>
<div class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-execution_count="79">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TransferCNN(nn.Module):</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, conv_dilation<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.feature_embeddings <span class="op">=</span> nn.Sequential(</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">256</span>, <span class="dv">128</span>, <span class="dv">2</span>, dilation<span class="op">=</span>conv_dilation),</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>            nn.Mish(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">128</span>, <span class="dv">64</span>, <span class="dv">2</span>),</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>            nn.Mish(inplace<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># programmatically get feature embedding size </span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._feature_embed_size <span class="op">=</span> <span class="bu">list</span>(<span class="va">self</span>.feature_embeddings(torch.rand(<span class="dv">1</span>, <span class="dv">256</span>, <span class="dv">6</span>, <span class="dv">6</span>)).detach().size())</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedding_size <span class="op">=</span> np.prod(<span class="va">self</span>._feature_embed_size)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># use dropout to regularize model </span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(p<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flatten <span class="op">=</span> nn.Flatten()</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># autoencoder like architecture - just remove reconstruction layers</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="va">self</span>.embedding_size, <span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">2</span>)</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act1 <span class="op">=</span> nn.Mish()</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">2</span>, <span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">4</span>)</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act2 <span class="op">=</span> nn.Mish()</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc3 <span class="op">=</span> nn.Linear(<span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">4</span>, <span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">4</span>)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act3 <span class="op">=</span> nn.Mish()</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc4 <span class="op">=</span> nn.Linear(<span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">4</span>, <span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">2</span>)</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act4 <span class="op">=</span> nn.Mish()</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc5 <span class="op">=</span> nn.Linear(<span class="va">self</span>.embedding_size<span class="op">//</span><span class="dv">2</span>, <span class="dv">9</span>)</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># create latent space rep.</span></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.flatten(<span class="va">self</span>.feature_embeddings(<span class="bu">input</span>))</span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.act1(<span class="va">self</span>.fc1(z))</span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.dropout(z)</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.act2(<span class="va">self</span>.fc2(z))</span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.dropout(z)</span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.act3(<span class="va">self</span>.fc3(z))</span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.dropout(z)</span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.act4(<span class="va">self</span>.fc4(z))</span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.dropout(z)</span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.fc5(z)</span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> TransferCNN().to(<span class="st">"cuda:0"</span>)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>summary(model, (<span class="dv">1</span>, <span class="dv">256</span>, <span class="dv">6</span>, <span class="dv">6</span>), verbose<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TransferCNN                              [1, 9]                    --
├─Sequential: 1-1                        [1, 64, 3, 3]             --
│    └─Conv2d: 2-1                       [1, 128, 4, 4]            131,200
│    └─Mish: 2-2                         [1, 128, 4, 4]            --
│    └─Conv2d: 2-3                       [1, 64, 3, 3]             32,832
│    └─Mish: 2-4                         [1, 64, 3, 3]             --
├─Flatten: 1-2                           [1, 576]                  --
├─Linear: 1-3                            [1, 288]                  166,176
├─Mish: 1-4                              [1, 288]                  --
├─Dropout: 1-5                           [1, 288]                  --
├─Linear: 1-6                            [1, 144]                  41,616
├─Mish: 1-7                              [1, 144]                  --
├─Dropout: 1-8                           [1, 144]                  --
├─Linear: 1-9                            [1, 144]                  20,880
├─Mish: 1-10                             [1, 144]                  --
├─Dropout: 1-11                          [1, 144]                  --
├─Linear: 1-12                           [1, 288]                  41,760
├─Mish: 1-13                             [1, 288]                  --
├─Dropout: 1-14                          [1, 288]                  --
├─Linear: 1-15                           [1, 9]                    2,601
==========================================================================================
Total params: 437,065
Trainable params: 437,065
Non-trainable params: 0
Total mult-adds (M): 2.67
==========================================================================================
Input size (MB): 0.04
Forward/backward pass size (MB): 0.03
Params size (MB): 1.75
Estimated Total Size (MB): 1.81
==========================================================================================</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="80">
<pre><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TransferCNN                              [1, 9]                    --
├─Sequential: 1-1                        [1, 64, 3, 3]             --
│    └─Conv2d: 2-1                       [1, 128, 4, 4]            131,200
│    └─Mish: 2-2                         [1, 128, 4, 4]            --
│    └─Conv2d: 2-3                       [1, 64, 3, 3]             32,832
│    └─Mish: 2-4                         [1, 64, 3, 3]             --
├─Flatten: 1-2                           [1, 576]                  --
├─Linear: 1-3                            [1, 288]                  166,176
├─Mish: 1-4                              [1, 288]                  --
├─Dropout: 1-5                           [1, 288]                  --
├─Linear: 1-6                            [1, 144]                  41,616
├─Mish: 1-7                              [1, 144]                  --
├─Dropout: 1-8                           [1, 144]                  --
├─Linear: 1-9                            [1, 144]                  20,880
├─Mish: 1-10                             [1, 144]                  --
├─Dropout: 1-11                          [1, 144]                  --
├─Linear: 1-12                           [1, 288]                  41,760
├─Mish: 1-13                             [1, 288]                  --
├─Dropout: 1-14                          [1, 288]                  --
├─Linear: 1-15                           [1, 9]                    2,601
==========================================================================================
Total params: 437,065
Trainable params: 437,065
Non-trainable params: 0
Total mult-adds (M): 2.67
==========================================================================================
Input size (MB): 0.04
Forward/backward pass size (MB): 0.03
Params size (MB): 1.75
Estimated Total Size (MB): 1.81
==========================================================================================</code></pre>
</div>
</div>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> model(train_embeds)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>prob <span class="op">=</span> F.softmax(output)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">max</span>(prob, <span class="dv">1</span>)[<span class="dv">1</span>].detach()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\ericz\AppData\Local\Temp\ipykernel_16976\3956553545.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  prob = F.softmax(output)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="part-c---5-pt" class="level3">
<h3 class="anchored" data-anchor-id="part-c---5-pt">Part (c) - 5 pt</h3>
<p>Train your new network, including any hyperparameter tuning. Plot and submit the training curve of your best model only.</p>
<p>Note: Depending on how you are caching (saving) your AlexNet features, PyTorch might still be tracking updates to the <strong>AlexNet weights</strong>, which we are not tuning. One workaround is to convert your AlexNet feature tensor into a numpy array, and then back into a PyTorch tensor.</p>
<div class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-execution_count="87">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_loss(preds, targets):</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> criterion(preds, targets)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> transfer_train_loop(train_data, val_data, convolution_dilation<span class="op">=</span><span class="dv">2</span>, epochs<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.02</span>, momentum<span class="op">=</span><span class="fl">0.95</span>, wd<span class="op">=</span><span class="fl">1e-4</span>, batch_size<span class="op">=</span><span class="va">None</span>, use_cuda<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> use_cuda <span class="kw">and</span> torch.cuda.is_available():</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>        dev <span class="op">=</span> <span class="st">"cuda:0"</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"CUDA unavailable, training on CPU"</span>)</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>        dev <span class="op">=</span> <span class="st">"CPU"</span></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(dev)</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>    network <span class="op">=</span> TransferCNN(conv_dilation<span class="op">=</span>convolution_dilation)</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>    network <span class="op">=</span> network.to(device)</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.SGD(network.parameters(</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>    ), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span>momentum, weight_decay<span class="op">=</span>wd)</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> train_data <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>        summary(network, input_data<span class="op">=</span>train_data[<span class="dv">0</span>], verbose<span class="op">=</span><span class="dv">1</span>, device<span class="op">=</span>device)</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>    loss_dict <span class="op">=</span> {<span class="st">"config"</span>: <span class="ss">f"Convolution Dilation: </span><span class="sc">{</span>convolution_dilation<span class="sc">}</span><span class="ss">, Epochs: </span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss">, Lr: </span><span class="sc">{</span>learning_rate<span class="sc">}</span><span class="ss">, Momentum:</span><span class="sc">{</span>momentum<span class="sc">}</span><span class="ss">, Weight Decay: </span><span class="sc">{</span>wd<span class="sc">}</span><span class="ss">, Batch Size: </span><span class="sc">{</span>batch_size<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"train_loss"</span>: [], <span class="st">"val_loss"</span>: [],</span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"train_acc"</span>: [], <span class="st">"val_acc"</span>: []}</span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> trange(epochs, desc<span class="op">=</span><span class="st">"Train epochs"</span>, unit<span class="op">=</span><span class="st">"epoch"</span>) <span class="im">as</span> train_bar:</span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> train_bar:</span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a>            epoch_loss, val_loss <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">0.0</span></span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a>            train_correct, train_total <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">0.0</span></span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a>            val_correct, val_total <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">0.0</span></span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># reenable train mode to enable dropout</span></span>
<span id="cb44-33"><a href="#cb44-33" aria-hidden="true" tabindex="-1"></a>            network.train()</span>
<span id="cb44-34"><a href="#cb44-34" aria-hidden="true" tabindex="-1"></a>            inputs, targets <span class="op">=</span> train_data</span>
<span id="cb44-35"><a href="#cb44-35" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> inputs.to(device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-36"><a href="#cb44-36" aria-hidden="true" tabindex="-1"></a>            targets <span class="op">=</span> targets.to(device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-37"><a href="#cb44-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-38"><a href="#cb44-38" aria-hidden="true" tabindex="-1"></a>            network.zero_grad()</span>
<span id="cb44-39"><a href="#cb44-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-40"><a href="#cb44-40" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> network(inputs)</span>
<span id="cb44-41"><a href="#cb44-41" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> compute_loss(preds, targets)</span>
<span id="cb44-42"><a href="#cb44-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-43"><a href="#cb44-43" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb44-44"><a href="#cb44-44" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb44-45"><a href="#cb44-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-46"><a href="#cb44-46" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb44-47"><a href="#cb44-47" aria-hidden="true" tabindex="-1"></a>                <span class="co"># eval mode to disable dropout</span></span>
<span id="cb44-48"><a href="#cb44-48" aria-hidden="true" tabindex="-1"></a>                network.<span class="bu">eval</span>()</span>
<span id="cb44-49"><a href="#cb44-49" aria-hidden="true" tabindex="-1"></a>                epoch_loss <span class="op">+=</span> loss.item()</span>
<span id="cb44-50"><a href="#cb44-50" aria-hidden="true" tabindex="-1"></a>                _, category_preds <span class="op">=</span> torch.<span class="bu">max</span>(preds, <span class="dv">1</span>)</span>
<span id="cb44-51"><a href="#cb44-51" aria-hidden="true" tabindex="-1"></a>                train_correct <span class="op">+=</span> <span class="bu">float</span>((category_preds <span class="op">==</span></span>
<span id="cb44-52"><a href="#cb44-52" aria-hidden="true" tabindex="-1"></a>                                        targets).<span class="bu">sum</span>().item())</span>
<span id="cb44-53"><a href="#cb44-53" aria-hidden="true" tabindex="-1"></a>                train_total <span class="op">+=</span> <span class="bu">float</span>(<span class="bu">len</span>(preds))</span>
<span id="cb44-54"><a href="#cb44-54" aria-hidden="true" tabindex="-1"></a>                loss_dict[<span class="st">"train_loss"</span>].append(loss.item())</span>
<span id="cb44-55"><a href="#cb44-55" aria-hidden="true" tabindex="-1"></a>                loss_dict[<span class="st">"train_acc"</span>].append(train_correct<span class="op">/</span>train_total)</span>
<span id="cb44-56"><a href="#cb44-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-57"><a href="#cb44-57" aria-hidden="true" tabindex="-1"></a>                inputs, targets <span class="op">=</span> val_data</span>
<span id="cb44-58"><a href="#cb44-58" aria-hidden="true" tabindex="-1"></a>                inputs <span class="op">=</span> inputs.to(device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-59"><a href="#cb44-59" aria-hidden="true" tabindex="-1"></a>                targets <span class="op">=</span> targets.to(device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-60"><a href="#cb44-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-61"><a href="#cb44-61" aria-hidden="true" tabindex="-1"></a>                preds <span class="op">=</span> network(inputs)</span>
<span id="cb44-62"><a href="#cb44-62" aria-hidden="true" tabindex="-1"></a>                batch_val_loss <span class="op">=</span> compute_loss(preds, targets).item()</span>
<span id="cb44-63"><a href="#cb44-63" aria-hidden="true" tabindex="-1"></a>                val_loss <span class="op">+=</span> batch_val_loss</span>
<span id="cb44-64"><a href="#cb44-64" aria-hidden="true" tabindex="-1"></a>                _, category_preds <span class="op">=</span> torch.<span class="bu">max</span>(preds, <span class="dv">1</span>)</span>
<span id="cb44-65"><a href="#cb44-65" aria-hidden="true" tabindex="-1"></a>                val_correct <span class="op">+=</span> <span class="bu">float</span>((category_preds <span class="op">==</span></span>
<span id="cb44-66"><a href="#cb44-66" aria-hidden="true" tabindex="-1"></a>                                        targets).<span class="bu">sum</span>().item())</span>
<span id="cb44-67"><a href="#cb44-67" aria-hidden="true" tabindex="-1"></a>                val_total <span class="op">+=</span> <span class="bu">float</span>(<span class="bu">len</span>(preds))</span>
<span id="cb44-68"><a href="#cb44-68" aria-hidden="true" tabindex="-1"></a>                loss_dict[<span class="st">"val_loss"</span>].append(batch_val_loss)</span>
<span id="cb44-69"><a href="#cb44-69" aria-hidden="true" tabindex="-1"></a>                loss_dict[<span class="st">"val_acc"</span>].append(val_correct<span class="op">/</span>val_total)</span>
<span id="cb44-70"><a href="#cb44-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-71"><a href="#cb44-71" aria-hidden="true" tabindex="-1"></a>            train_bar.set_postfix(epoch_loss<span class="op">=</span>epoch_loss,</span>
<span id="cb44-72"><a href="#cb44-72" aria-hidden="true" tabindex="-1"></a>                                  train_acc<span class="op">=</span>train_correct<span class="op">/</span>train_total,</span>
<span id="cb44-73"><a href="#cb44-73" aria-hidden="true" tabindex="-1"></a>                                  train_correct<span class="op">=</span>train_correct,</span>
<span id="cb44-74"><a href="#cb44-74" aria-hidden="true" tabindex="-1"></a>                                  train_total<span class="op">=</span>train_total,</span>
<span id="cb44-75"><a href="#cb44-75" aria-hidden="true" tabindex="-1"></a>                                  val_loss<span class="op">=</span>val_loss,</span>
<span id="cb44-76"><a href="#cb44-76" aria-hidden="true" tabindex="-1"></a>                                  val_acc<span class="op">=</span>val_correct<span class="op">/</span>val_total)</span>
<span id="cb44-77"><a href="#cb44-77" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> network, loss_dict</span>
<span id="cb44-78"><a href="#cb44-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-79"><a href="#cb44-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-80"><a href="#cb44-80" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_transfer_test_performance(network, test_data):</span>
<span id="cb44-81"><a href="#cb44-81" aria-hidden="true" tabindex="-1"></a>    test_correct, test_total <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">0.0</span></span>
<span id="cb44-82"><a href="#cb44-82" aria-hidden="true" tabindex="-1"></a>    test_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb44-83"><a href="#cb44-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-84"><a href="#cb44-84" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> <span class="bu">next</span>(network.parameters()).device</span>
<span id="cb44-85"><a href="#cb44-85" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb44-86"><a href="#cb44-86" aria-hidden="true" tabindex="-1"></a>        <span class="co"># disable dropout for test time</span></span>
<span id="cb44-87"><a href="#cb44-87" aria-hidden="true" tabindex="-1"></a>        network.<span class="bu">eval</span>()</span>
<span id="cb44-88"><a href="#cb44-88" aria-hidden="true" tabindex="-1"></a>        inputs, targets <span class="op">=</span> test_data</span>
<span id="cb44-89"><a href="#cb44-89" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> inputs.to(device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-90"><a href="#cb44-90" aria-hidden="true" tabindex="-1"></a>        targets <span class="op">=</span> targets.to(device, non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-91"><a href="#cb44-91" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> network(inputs)</span>
<span id="cb44-92"><a href="#cb44-92" aria-hidden="true" tabindex="-1"></a>        test_loss <span class="op">+=</span> compute_loss(preds, targets).item()</span>
<span id="cb44-93"><a href="#cb44-93" aria-hidden="true" tabindex="-1"></a>        _, category_preds <span class="op">=</span> torch.<span class="bu">max</span>(preds, <span class="dv">1</span>)</span>
<span id="cb44-94"><a href="#cb44-94" aria-hidden="true" tabindex="-1"></a>        test_correct <span class="op">+=</span> <span class="bu">float</span>((category_preds <span class="op">==</span> targets).<span class="bu">sum</span>().item())</span>
<span id="cb44-95"><a href="#cb44-95" aria-hidden="true" tabindex="-1"></a>        test_total <span class="op">+=</span> <span class="bu">len</span>(preds)</span>
<span id="cb44-96"><a href="#cb44-96" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> test_correct<span class="op">/</span>test_total, test_correct, test_total, test_loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>train_embeds, val_embeds <span class="op">=</span> torch.tensor(train_embeds.detach()), torch.tensor(val_embeds.detach())</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>transfer_model, loss_dict_transfer <span class="op">=</span> transfer_train_loop((train_embeds, train_targets), (val_embeds, val_targets))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\ericz\AppData\Local\Temp\ipykernel_16976\3592352514.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_embeds, val_embeds = torch.tensor(train_embeds.detach()), torch.tensor(val_embeds.detach())</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TransferCNN                              [1554, 9]                 --
├─Sequential: 1-1                        [1554, 64, 3, 3]          --
│    └─Conv2d: 2-1                       [1554, 128, 4, 4]         131,200
│    └─Mish: 2-2                         [1554, 128, 4, 4]         --
│    └─Conv2d: 2-3                       [1554, 64, 3, 3]          32,832
│    └─Mish: 2-4                         [1554, 64, 3, 3]          --
├─Flatten: 1-2                           [1554, 576]               --
├─Linear: 1-3                            [1554, 288]               166,176
├─Mish: 1-4                              [1554, 288]               --
├─Dropout: 1-5                           [1554, 288]               --
├─Linear: 1-6                            [1554, 144]               41,616
├─Mish: 1-7                              [1554, 144]               --
├─Dropout: 1-8                           [1554, 144]               --
├─Linear: 1-9                            [1554, 144]               20,880
├─Mish: 1-10                             [1554, 144]               --
├─Dropout: 1-11                          [1554, 144]               --
├─Linear: 1-12                           [1554, 288]               41,760
├─Mish: 1-13                             [1554, 288]               --
├─Dropout: 1-14                          [1554, 288]               --
├─Linear: 1-15                           [1554, 9]                 2,601
==========================================================================================
Total params: 437,065
Trainable params: 437,065
Non-trainable params: 0
Total mult-adds (G): 4.15
==========================================================================================
Input size (MB): 57.29
Forward/backward pass size (MB): 43.47
Params size (MB): 1.75
Estimated Total Size (MB): 102.51
==========================================================================================</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Train epochs: 100%|██████████| 1000/1000 [00:06&lt;00:00, 143.75epoch/s, epoch_loss=3.84e-10, train_acc=1, train_correct=1554.0, train_total=1554.0, val_acc=1, val_loss=0]    </code></pre>
</div>
</div>
<div class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>plot_train_curves(loss_dict_transfer)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>plot_val_curves(loss_dict_transfer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Lab3_files/figure-html/cell-29-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Lab3_files/figure-html/cell-29-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="part-d---2-pt-1" class="level3">
<h3 class="anchored" data-anchor-id="part-d---2-pt-1">Part (d) - 2 pt</h3>
<p>Report the test accuracy of your best model. How does the test accuracy compare to Part 3(d) without transfer learning?</p>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>test_embeds <span class="op">=</span> torch.tensor(test_embeds.clone().detach())</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>test_accuracy, _, _, test_loss <span class="op">=</span> compute_transfer_test_performance(transfer_model, (test_embeds, test_targets))</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_accuracy, test_loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.0 0.0</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\ericz\AppData\Local\Temp\ipykernel_16976\940114777.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  test_embeds = torch.tensor(test_embeds.clone().detach())</code></pre>
</div>
</div>
<p>The transfer learning model performed as the model from part 3(d), i.e., both achieved 100% on the test set. So both models did exceptionally well!</p>
</section>
<section id="additional-testing-5-pt" class="level3">
<h3 class="anchored" data-anchor-id="additional-testing-5-pt">5. Additional Testing [5 pt]</h3>
<p>As a final step in testing we will be revisiting the sample images that you had collected and submitted at the start of this lab. These sample images should be untouched and will be used to demonstrate how well your model works at identifying your hand guestures.</p>
<p>Using the best transfer learning model developed in Part 4. Report the test accuracy on your sample images and how it compares to the test accuracy obtained in Part 4(d)? How well did your model do for the different hand guestures? Provide an explanation for why you think your model performed the way it did?</p>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>